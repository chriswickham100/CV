{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "658f48bc",
   "metadata": {},
   "source": [
    "# Pandas Bible\n",
    "\n",
    "This notebook is meant to capture and easily categorize every possibility for a Pandas-based job interview. \n",
    "\n",
    "This is the information I have about the assessment: \"Itâ€™s a simple test (1-2 hours) using the Pandas library with a simple data set to ensure you are familiar with the basic concepts and show good form in your code.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b064e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898f6562",
   "metadata": {},
   "source": [
    "#### Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "070821d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# load the training dataset\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/ml-basics/daily-bike-share.csv;\n",
    "bike_data = pd.read_csv('daily-bike-share.csv')\n",
    "\n",
    "# load the training dataset\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/ml-basics/diabetes.csv;\n",
    "diabetes = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# load the training dataset\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/ml-basics/penguins.csv;\n",
    "penguins = pd.read_csv('penguins.csv')\n",
    "\n",
    "# load the training dataset\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/ml-basics/seeds.csv;\n",
    "data = pd.read_csv('seeds.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca467af6",
   "metadata": {},
   "source": [
    "### Importing and Creating Datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3e9077",
   "metadata": {},
   "source": [
    "##### wget and read_csv\n",
    "\n",
    "You can use the wget! to import a dataset from Github (where wget is a bash command and ! calls bash in a Python notebook), and read_csv to read a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04f68fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/ml-basics/grades.csv\n",
    "df_students = pd.read_csv('grades.csv',delimiter=',',header='infer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ffc0c7",
   "metadata": {},
   "source": [
    "#### Creating a 1D Numpy Array from a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "373587b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [50,50,47,97,49,3,53,42,26,74,82,62,37,15,70,27,36,35,48,52,63,64]\n",
    "\n",
    "grades = np.array(data) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff23f71",
   "metadata": {},
   "source": [
    "#### Create a 2D Numpy Array from two lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a336c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_hours = [10.0,11.5,9.0,16.0,9.25,1.0,11.5,9.0,8.5,14.5,15.5,\n",
    "               13.75,9.0,8.0,15.5,8.0,9.0,6.0,10.0,23.2,12.5,12.0]\n",
    "\n",
    "student_data = np.array([study_hours, grades])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05af497b",
   "metadata": {},
   "source": [
    "#### Create a Pandas Dataframe from three lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e7dd8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_students = pd.DataFrame({'Name': ['Dan', 'Joann', 'Pedro', 'Rosie', 'Ethan', 'Vicky', 'Frederic', 'Jimmie', \n",
    "                                     'Rhonda', 'Giovanni', 'Francesca', 'Rajab', 'Naiyana', 'Kian', 'Jenny',\n",
    "                                     'Jakeem','','Ismat','Anila','Skye','Daniel','Aisha'],\n",
    "                            'StudyHours':student_data[0],\n",
    "                            'Grade':student_data[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318ce930",
   "metadata": {},
   "source": [
    "### Dealing with Missing Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7133e072",
   "metadata": {},
   "source": [
    "##### Show the DataFrame as Booleans where there is missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cbb6485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>StudyHours</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  StudyHours  Grade\n",
       "0   False       False  False\n",
       "1   False       False  False\n",
       "2   False       False  False\n",
       "3   False       False  False\n",
       "4   False       False  False\n",
       "5   False       False  False\n",
       "6   False       False  False\n",
       "7   False       False  False\n",
       "8   False       False  False\n",
       "9   False       False  False\n",
       "10  False       False  False\n",
       "11  False       False  False\n",
       "12  False       False  False\n",
       "13  False       False  False\n",
       "14  False       False  False\n",
       "15  False       False  False\n",
       "16  False       False  False\n",
       "17  False       False  False\n",
       "18  False       False  False\n",
       "19  False       False  False\n",
       "20  False       False  False\n",
       "21  False       False  False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_students.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3225b431",
   "metadata": {},
   "source": [
    "##### Show the sum of null values by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9c4c9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name          0\n",
       "StudyHours    0\n",
       "Grade         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_students.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609a3c1d",
   "metadata": {},
   "source": [
    "##### Show the rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40b7ea65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>StudyHours</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, StudyHours, Grade]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_students[df_students.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41878a4e",
   "metadata": {},
   "source": [
    "##### Fill the null fields with a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd520650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>StudyHours</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  StudyHours  Grade\n",
       "0  False       False  False\n",
       "1  False       False  False\n",
       "2  False       False  False\n",
       "3  False       False  False\n",
       "4  False       False  False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This line fills a particular column of the dataframe with that dataframe's mean\n",
    "df_students.StudyHours = df_students.StudyHours.fillna(df_students.StudyHours.mean())\n",
    "df_students.isnull().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dad974",
   "metadata": {},
   "source": [
    "##### Drop nulls from any row with a Null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8eecb8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>StudyHours</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  StudyHours  Grade\n",
       "0  False       False  False\n",
       "1  False       False  False\n",
       "2  False       False  False\n",
       "3  False       False  False\n",
       "4  False       False  False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_students = df_students.dropna(axis=0, how='any')\n",
    "df_students.isnull().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb811b0",
   "metadata": {},
   "source": [
    "### Initial Exploration "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e03c7ba",
   "metadata": {},
   "source": [
    "### Querying by Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54facfff",
   "metadata": {},
   "source": [
    "#### Find a row by its index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "065c9ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>StudyHours</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dan</td>\n",
       "      <td>10.00</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joann</td>\n",
       "      <td>11.50</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pedro</td>\n",
       "      <td>9.00</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rosie</td>\n",
       "      <td>16.00</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ethan</td>\n",
       "      <td>9.25</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  StudyHours  Grade\n",
       "0    Dan       10.00   50.0\n",
       "1  Joann       11.50   50.0\n",
       "2  Pedro        9.00   47.0\n",
       "3  Rosie       16.00   97.0\n",
       "4  Ethan        9.25   49.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_students.loc[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fd0708c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name          Vicky\n",
       "StudyHours      1.0\n",
       "Grade           3.0\n",
       "Name: 5, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_students.loc[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddcc46c",
   "metadata": {},
   "source": [
    "#### Find a row by index and column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df6830aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_students.loc[5,'Grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8dc14df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    50.0\n",
       "2    47.0\n",
       "3    97.0\n",
       "Name: Grade, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_students.loc[1:3,'Grade']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cc799a",
   "metadata": {},
   "source": [
    "#### Find a row by index and condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "399af200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>StudyHours</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Aisha</td>\n",
       "      <td>12.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  StudyHours  Grade\n",
       "21  Aisha        12.0   64.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_students.loc[df_students['Name']=='Aisha']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe837c32",
   "metadata": {},
   "source": [
    "#### Filtering a dataframe based on multiple conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b1582d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights = pd.read_csv('flights.csv')\n",
    "df_flights = df_flights.loc[(df_flights.ArrDelay < 400) & (df_flights.DepDelay < 400)]                            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b911eb53",
   "metadata": {},
   "source": [
    "#### Query by column and condition (3 ways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ba7dd74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>StudyHours</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Aisha</td>\n",
       "      <td>12.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  StudyHours  Grade\n",
       "21  Aisha        12.0   64.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_students.query('Name==\"Aisha\"')\n",
    "df_students[df_students.Name == 'Aisha']\n",
    "df_students[df_students['Name']=='Aisha']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6d86a4",
   "metadata": {},
   "source": [
    "#### Query sequential rows by ordinal position in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81093d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>StudyHours</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dan</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joann</td>\n",
       "      <td>11.5</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pedro</td>\n",
       "      <td>9.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rosie</td>\n",
       "      <td>16.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  StudyHours  Grade\n",
       "0    Dan        10.0   50.0\n",
       "1  Joann        11.5   50.0\n",
       "2  Pedro         9.0   47.0\n",
       "3  Rosie        16.0   97.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_students.iloc[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7391bd60",
   "metadata": {},
   "source": [
    "#### Query sequent rows and columns by ordinal position in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b04f7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>StudyHours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dan</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joann</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pedro</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rosie</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  StudyHours\n",
       "0    Dan        10.0\n",
       "1  Joann        11.5\n",
       "2  Pedro         9.0\n",
       "3  Rosie        16.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_students.iloc[0:4,0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884ebe91",
   "metadata": {},
   "source": [
    "#### Query nonsequential rows and columns by ordinal position in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "349d0a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joann</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ethan</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  Grade\n",
       "1  Joann   50.0\n",
       "4  Ethan   49.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_students.iloc[[1,4],[0,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d6955e",
   "metadata": {},
   "source": [
    "#### Filter by a Boolean and find the new mean of a column in that dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "892085f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_study = df_students.StudyHours.mean()\n",
    "df_students[df_students.StudyHours > mean_study].Grade.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f544ae",
   "metadata": {},
   "source": [
    "### DataFrame Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4141a7c",
   "metadata": {},
   "source": [
    "#### Create Pandas Series based on a condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08cfab5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3     True\n",
       "4    False\n",
       "Name: Grade, dtype: bool"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passes = pd.Series(df_students['Grade']>=60)\n",
    "type(passes)\n",
    "passes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0787ee",
   "metadata": {},
   "source": [
    "#### Concatenate that series to an existing Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d31db9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>StudyHours</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Pass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dan</td>\n",
       "      <td>10.00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joann</td>\n",
       "      <td>11.50</td>\n",
       "      <td>50.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pedro</td>\n",
       "      <td>9.00</td>\n",
       "      <td>47.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rosie</td>\n",
       "      <td>16.00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ethan</td>\n",
       "      <td>9.25</td>\n",
       "      <td>49.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  StudyHours  Grade   Pass\n",
       "0    Dan       10.00   50.0  False\n",
       "1  Joann       11.50   50.0  False\n",
       "2  Pedro        9.00   47.0  False\n",
       "3  Rosie       16.00   97.0   True\n",
       "4  Ethan        9.25   49.0  False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_students = pd.concat([df_students, passes.rename(\"Pass\")],axis=1) \n",
    "df_students.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cc0431",
   "metadata": {},
   "source": [
    "#### Show the datatype of a Pandas dataframe and test if a column is a float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d8ace77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name           object\n",
      "StudyHours    float64\n",
      "Grade         float64\n",
      "Pass             bool\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_students.dtypes)\n",
    "df_students.StudyHours.dtypes == 'float64'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d686b7",
   "metadata": {},
   "source": [
    "#### Add a dataframe to the bottom of another dataframe (and reset the index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbe1f0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>StudyHours</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Pass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dan</td>\n",
       "      <td>10.00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joann</td>\n",
       "      <td>11.50</td>\n",
       "      <td>50.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pedro</td>\n",
       "      <td>9.00</td>\n",
       "      <td>47.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rosie</td>\n",
       "      <td>16.00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ethan</td>\n",
       "      <td>9.25</td>\n",
       "      <td>49.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  StudyHours  Grade   Pass\n",
       "0    Dan       10.00   50.0  False\n",
       "1  Joann       11.50   50.0  False\n",
       "2  Pedro        9.00   47.0  False\n",
       "3  Rosie       16.00   97.0   True\n",
       "4  Ethan        9.25   49.0  False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_students = pd.concat([df_students, df_students.head()],axis=0) \n",
    "more_students.reset_index()\n",
    "more_students = more_students.iloc[:,0:4]\n",
    "more_students.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6b2fd5",
   "metadata": {},
   "source": [
    "#### Groupby count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8fb2d803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass\n",
      "False    15\n",
      "True      7\n",
      "Name: Name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_students.groupby(df_students.Pass).Name.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f70f605",
   "metadata": {},
   "source": [
    "#### Groupby one column and show the means of two quantitative columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b56ad2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       StudyHours      Grade\n",
      "Pass                        \n",
      "False        9.53  38.000000\n",
      "True        14.25  73.142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x3/d55ycfh10xl3qzrrp818k8xw0000gn/T/ipykernel_11829/2502225861.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  print(df_students.groupby(df_students.Pass)['StudyHours', 'Grade'].mean())\n"
     ]
    }
   ],
   "source": [
    "print(df_students.groupby(df_students.Pass)['StudyHours', 'Grade'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ae46a4",
   "metadata": {},
   "source": [
    "#### Create a grouped dataframe using one column and get a group from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee0b653c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>StudyHours</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Pass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dan</td>\n",
       "      <td>10.00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joann</td>\n",
       "      <td>11.50</td>\n",
       "      <td>50.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pedro</td>\n",
       "      <td>9.00</td>\n",
       "      <td>47.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ethan</td>\n",
       "      <td>9.25</td>\n",
       "      <td>49.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Vicky</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  StudyHours  Grade   Pass\n",
       "0    Dan       10.00   50.0  False\n",
       "1  Joann       11.50   50.0  False\n",
       "2  Pedro        9.00   47.0  False\n",
       "4  Ethan        9.25   49.0  False\n",
       "5  Vicky        1.00    3.0  False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf = df_students.groupby('Pass') \n",
    "gdf.get_group(False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08878d2b",
   "metadata": {},
   "source": [
    "#### Create a grouped dataframe using two columns  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f079a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>StudyHours</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Pass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Vicky</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  StudyHours  Grade   Pass\n",
       "5  Vicky         1.0    3.0  False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf = df_students.groupby(['Pass','StudyHours'])\n",
    "gdf.get_group((False, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7016479b",
   "metadata": {},
   "source": [
    "#### Sort "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb73f871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>StudyHours</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Pass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rosie</td>\n",
       "      <td>16.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Francesca</td>\n",
       "      <td>15.5</td>\n",
       "      <td>82.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Giovanni</td>\n",
       "      <td>14.5</td>\n",
       "      <td>74.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Jenny</td>\n",
       "      <td>15.5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Aisha</td>\n",
       "      <td>12.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name  StudyHours  Grade  Pass\n",
       "3       Rosie        16.0   97.0  True\n",
       "10  Francesca        15.5   82.0  True\n",
       "9    Giovanni        14.5   74.0  True\n",
       "14      Jenny        15.5   70.0  True\n",
       "21      Aisha        12.0   64.0  True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_students = df_students.sort_values('Grade', ascending=False)\n",
    "df_students.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c072118",
   "metadata": {},
   "source": [
    "#### Use Scikit learn to normalize dataframe columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7313959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a sample of data students where StudyHours are just >1 \n",
    "df_sample = df_students[df_students['StudyHours']>1]\n",
    "\n",
    "# Get a scaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Create a new dataframe for the scaled values\n",
    "df_normalized = df_sample[['Name', 'Grade', 'StudyHours']].copy()\n",
    "\n",
    "# Normalize the numeric columns\n",
    "df_normalized[['Grade','StudyHours']] = scaler.fit_transform(df_normalized[['Grade','StudyHours']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8245ec5d",
   "metadata": {},
   "source": [
    "#### Use sklearn to split into features and target, then training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4bf5ef93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      "[[1.       1.       0.       6.       0.       2.       0.344167 0.363625\n",
      "  0.805833 0.160446]\n",
      " [1.       1.       0.       0.       0.       2.       0.363478 0.353739\n",
      "  0.696087 0.248539]\n",
      " [1.       1.       0.       1.       1.       1.       0.196364 0.189405\n",
      "  0.437273 0.248309]]\n",
      "\n",
      "Labels:\n",
      "[331 131 120]\n",
      "Training Set: 511 rows\n",
      "Test Set: 220 rows\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = bike_data[['season','mnth', 'holiday','weekday','workingday','weathersit','temp', 'atemp', 'hum', 'windspeed']].values, bike_data['rentals'].values\n",
    "print('Features:',X[:3], '\\nLabels:', y[:3], sep='\\n')\n",
    "# Split data 70%-30% into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "print ('Training Set: %d rows\\nTest Set: %d rows' % (X_train.shape[0], X_test.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276be855",
   "metadata": {},
   "source": [
    "#### Separate features and labels for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5b6af2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "features = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']\n",
    "label = 'Diabetic'\n",
    "X, y = diabetes[features].values, diabetes[label].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d401ec8",
   "metadata": {},
   "source": [
    "#### Create a new variable, day, from a date variable using datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "84fec9ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>rentals</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1/1/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1/2/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1/3/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1/4/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1/5/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant    dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "0        1  1/1/2011       1   0     1        0        6           0   \n",
       "1        2  1/2/2011       1   0     1        0        0           0   \n",
       "2        3  1/3/2011       1   0     1        0        1           1   \n",
       "3        4  1/4/2011       1   0     1        0        2           1   \n",
       "4        5  1/5/2011       1   0     1        0        3           1   \n",
       "\n",
       "   weathersit      temp     atemp       hum  windspeed  rentals  day  \n",
       "0           2  0.344167  0.363625  0.805833   0.160446      331    1  \n",
       "1           2  0.363478  0.353739  0.696087   0.248539      131    2  \n",
       "2           1  0.196364  0.189405  0.437273   0.248309      120    3  \n",
       "3           1  0.200000  0.212122  0.590435   0.160296      108    4  \n",
       "4           1  0.226957  0.229270  0.436957   0.186900       82    5  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_data['day'] = pd.DatetimeIndex(bike_data['dteday']).day\n",
    "bike_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733f77e2",
   "metadata": {},
   "source": [
    "### Basic Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a025e2cb",
   "metadata": {},
   "source": [
    "#### Describe numerical columns in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34b30c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>rentals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.495385</td>\n",
       "      <td>0.474354</td>\n",
       "      <td>0.627894</td>\n",
       "      <td>0.190486</td>\n",
       "      <td>848.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.183051</td>\n",
       "      <td>0.162961</td>\n",
       "      <td>0.142429</td>\n",
       "      <td>0.077498</td>\n",
       "      <td>686.622488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.059130</td>\n",
       "      <td>0.079070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022392</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.337083</td>\n",
       "      <td>0.337842</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.134950</td>\n",
       "      <td>315.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.498333</td>\n",
       "      <td>0.486733</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.180975</td>\n",
       "      <td>713.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.655417</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>0.730209</td>\n",
       "      <td>0.233214</td>\n",
       "      <td>1096.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.861667</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>0.972500</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>3410.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             temp       atemp         hum   windspeed      rentals\n",
       "count  731.000000  731.000000  731.000000  731.000000   731.000000\n",
       "mean     0.495385    0.474354    0.627894    0.190486   848.176471\n",
       "std      0.183051    0.162961    0.142429    0.077498   686.622488\n",
       "min      0.059130    0.079070    0.000000    0.022392     2.000000\n",
       "25%      0.337083    0.337842    0.520000    0.134950   315.500000\n",
       "50%      0.498333    0.486733    0.626667    0.180975   713.000000\n",
       "75%      0.655417    0.608602    0.730209    0.233214  1096.000000\n",
       "max      0.861667    0.840896    0.972500    0.507463  3410.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features = ['temp', 'atemp', 'hum', 'windspeed']\n",
    "bike_data[numeric_features + ['rentals']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41a0bdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Find the mean of a column in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08961bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.031818181818181"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_study = df_students.StudyHours.mean()\n",
    "mean_grade = df_students.Grade.mean()\n",
    "mean_study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5fb602",
   "metadata": {},
   "source": [
    "#### Create a Pandas series and find min, max, mean, median, and mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7551d191",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = df_students['Grade']\n",
    "min_val = var.min()\n",
    "max_val = var.max()\n",
    "mean_val = var.mean()\n",
    "med_val = var.median()\n",
    "mod_val = var.mode()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e5ee0e",
   "metadata": {},
   "source": [
    "#### Show the 1st and 99th percentile of study hours in dataframe df_students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "70e9baaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first percentile: 2.05\n",
      "And this is the 99th: 21.69\n"
     ]
    }
   ],
   "source": [
    "q01 = df_students.StudyHours.quantile(0.01)\n",
    "q99 = df_students.StudyHours.quantile(0.99)\n",
    "print('This is the first percentile: {:.2f}\\nAnd this is the 99th: {:.2f}'.format(q01, q99))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1a4f76",
   "metadata": {},
   "source": [
    "#### Use iterrrows to print through rows in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "74ed2067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CulmenLength' 'CulmenDepth' 'FlipperLength' 'BodyMass' 'Species'] SpeciesName\n",
      "[ 43.5 15.2 213.0 4650.0 1 ] Gentoo\n",
      "[ 38.1 18.6 190.0 3700.0 0 ] Adelie\n",
      "[ 50.5 19.6 201.0 4050.0 2 ] Chinstrap\n",
      "[ 39.1 18.7 181.0 3750.0 ]\n",
      "[ 39.5 17.4 186.0 3800.0 ]\n",
      "[ 40.3 18.0 195.0 3250.0 ]\n",
      "[ nan nan nan nan ]\n",
      "[ 36.7 19.3 193.0 3450.0 ]\n",
      "[ 39.3 20.6 190.0 3650.0 ]\n",
      "[ 38.9 17.8 181.0 3625.0 ]\n",
      "[ 39.2 19.6 195.0 4675.0 ]\n",
      "[ 34.1 18.1 193.0 3475.0 ]\n",
      "[ 42.0 20.2 190.0 4250.0 ]\n",
      "[ 37.8 17.1 186.0 3300.0 ]\n",
      "[ 37.8 17.3 180.0 3700.0 ]\n",
      "[ 41.1 17.6 182.0 3200.0 ]\n",
      "[ 38.6 21.2 191.0 3800.0 ]\n",
      "[ 34.6 21.1 198.0 4400.0 ]\n",
      "[ 36.6 17.8 185.0 3700.0 ]\n",
      "[ 38.7 19.0 195.0 3450.0 ]\n",
      "[ 42.5 20.7 197.0 4500.0 ]\n",
      "[ 34.4 18.4 184.0 3325.0 ]\n",
      "[ 46.0 21.5 194.0 4200.0 ]\n",
      "[ 37.8 18.3 174.0 3400.0 ]\n",
      "[ 37.7 18.7 180.0 3600.0 ]\n",
      "[ 35.9 19.2 189.0 3800.0 ]\n",
      "[ 38.2 18.1 185.0 3950.0 ]\n",
      "[ 38.8 17.2 180.0 3800.0 ]\n",
      "[ 35.3 18.9 187.0 3800.0 ]\n",
      "[ 40.6 18.6 183.0 3550.0 ]\n",
      "[ 40.5 17.9 187.0 3200.0 ]\n",
      "[ 37.9 18.6 172.0 3150.0 ]\n",
      "[ 40.5 18.9 180.0 3950.0 ]\n",
      "[ 39.5 16.7 178.0 3250.0 ]\n",
      "[ 37.2 18.1 178.0 3900.0 ]\n",
      "[ 39.5 17.8 188.0 3300.0 ]\n",
      "[ 40.9 18.9 184.0 3900.0 ]\n",
      "[ 36.4 17.0 195.0 3325.0 ]\n",
      "[ 39.2 21.1 196.0 4150.0 ]\n",
      "[ 38.8 20.0 190.0 3950.0 ]\n",
      "[ 42.2 18.5 180.0 3550.0 ]\n",
      "[ 37.6 19.3 181.0 3300.0 ]\n",
      "[ 39.8 19.1 184.0 4650.0 ]\n",
      "[ 36.5 18.0 182.0 3150.0 ]\n",
      "[ 40.8 18.4 195.0 3900.0 ]\n",
      "[ 36.0 18.5 186.0 3100.0 ]\n",
      "[ 44.1 19.7 196.0 4400.0 ]\n",
      "[ 37.0 16.9 185.0 3000.0 ]\n",
      "[ 39.6 18.8 190.0 4600.0 ]\n",
      "[ 41.1 19.0 182.0 3425.0 ]\n",
      "[ 37.5 18.9 179.0 2975.0 ]\n",
      "[ 36.0 17.9 190.0 3450.0 ]\n",
      "[ 42.3 21.2 191.0 4150.0 ]\n",
      "[ 39.6 17.7 186.0 3500.0 ]\n",
      "[ 40.1 18.9 188.0 4300.0 ]\n",
      "[ 35.0 17.9 190.0 3450.0 ]\n",
      "[ 42.0 19.5 200.0 4050.0 ]\n",
      "[ 34.5 18.1 187.0 2900.0 ]\n",
      "[ 41.4 18.6 191.0 3700.0 ]\n",
      "[ 39.0 17.5 186.0 3550.0 ]\n",
      "[ 40.6 18.8 193.0 3800.0 ]\n",
      "[ 36.5 16.6 181.0 2850.0 ]\n",
      "[ 37.6 19.1 194.0 3750.0 ]\n",
      "[ 35.7 16.9 185.0 3150.0 ]\n",
      "[ 41.3 21.1 195.0 4400.0 ]\n",
      "[ 37.6 17.0 185.0 3600.0 ]\n",
      "[ 41.1 18.2 192.0 4050.0 ]\n",
      "[ 36.4 17.1 184.0 2850.0 ]\n",
      "[ 41.6 18.0 192.0 3950.0 ]\n",
      "[ 35.5 16.2 195.0 3350.0 ]\n",
      "[ 41.1 19.1 188.0 4100.0 ]\n",
      "[ 35.9 16.6 190.0 3050.0 ]\n",
      "[ 41.8 19.4 198.0 4450.0 ]\n",
      "[ 33.5 19.0 190.0 3600.0 ]\n",
      "[ 39.7 18.4 190.0 3900.0 ]\n",
      "[ 39.6 17.2 196.0 3550.0 ]\n",
      "[ 45.8 18.9 197.0 4150.0 ]\n",
      "[ 35.5 17.5 190.0 3700.0 ]\n",
      "[ 42.8 18.5 195.0 4250.0 ]\n",
      "[ 40.9 16.8 191.0 3700.0 ]\n",
      "[ 37.2 19.4 184.0 3900.0 ]\n",
      "[ 36.2 16.1 187.0 3550.0 ]\n",
      "[ 42.1 19.1 195.0 4000.0 ]\n",
      "[ 34.6 17.2 189.0 3200.0 ]\n",
      "[ 42.9 17.6 196.0 4700.0 ]\n",
      "[ 36.7 18.8 187.0 3800.0 ]\n",
      "[ 35.1 19.4 193.0 4200.0 ]\n",
      "[ 37.3 17.8 191.0 3350.0 ]\n",
      "[ 41.3 20.3 194.0 3550.0 ]\n",
      "[ 36.3 19.5 190.0 3800.0 ]\n",
      "[ 36.9 18.6 189.0 3500.0 ]\n",
      "[ 38.3 19.2 189.0 3950.0 ]\n",
      "[ 38.9 18.8 190.0 3600.0 ]\n",
      "[ 35.7 18.0 202.0 3550.0 ]\n",
      "[ 41.1 18.1 205.0 4300.0 ]\n",
      "[ 34.0 17.1 185.0 3400.0 ]\n",
      "[ 39.6 18.1 186.0 4450.0 ]\n",
      "[ 36.2 17.3 187.0 3300.0 ]\n",
      "[ 40.8 18.9 208.0 4300.0 ]\n",
      "[ 38.1 18.6 190.0 3700.0 ]\n",
      "[ 40.3 18.5 196.0 4350.0 ]\n",
      "[ 33.1 16.1 178.0 2900.0 ]\n",
      "[ 43.2 18.5 192.0 4100.0 ]\n",
      "[ 35.0 17.9 192.0 3725.0 ]\n",
      "[ 41.0 20.0 203.0 4725.0 ]\n",
      "[ 37.7 16.0 183.0 3075.0 ]\n",
      "[ 37.8 20.0 190.0 4250.0 ]\n",
      "[ 37.9 18.6 193.0 2925.0 ]\n",
      "[ 39.7 18.9 184.0 3550.0 ]\n",
      "[ 38.6 17.2 199.0 3750.0 ]\n",
      "[ 38.2 20.0 190.0 3900.0 ]\n",
      "[ 38.1 17.0 181.0 3175.0 ]\n",
      "[ 43.2 19.0 197.0 4775.0 ]\n",
      "[ 38.1 16.5 198.0 3825.0 ]\n",
      "[ 45.6 20.3 191.0 4600.0 ]\n",
      "[ 39.7 17.7 193.0 3200.0 ]\n",
      "[ 42.2 19.5 197.0 4275.0 ]\n",
      "[ 39.6 20.7 191.0 3900.0 ]\n",
      "[ 42.7 18.3 196.0 4075.0 ]\n",
      "[ 38.6 17.0 188.0 2900.0 ]\n",
      "[ 37.3 20.5 199.0 3775.0 ]\n",
      "[ 35.7 17.0 189.0 3350.0 ]\n",
      "[ 41.1 18.6 189.0 3325.0 ]\n",
      "[ 36.2 17.2 187.0 3150.0 ]\n",
      "[ 37.7 19.8 198.0 3500.0 ]\n",
      "[ 40.2 17.0 176.0 3450.0 ]\n",
      "[ 41.4 18.5 202.0 3875.0 ]\n",
      "[ 35.2 15.9 186.0 3050.0 ]\n",
      "[ 40.6 19.0 199.0 4000.0 ]\n",
      "[ 38.8 17.6 191.0 3275.0 ]\n",
      "[ 41.5 18.3 195.0 4300.0 ]\n",
      "[ 39.0 17.1 191.0 3050.0 ]\n",
      "[ 44.1 18.0 210.0 4000.0 ]\n",
      "[ 38.5 17.9 190.0 3325.0 ]\n",
      "[ 43.1 19.2 197.0 3500.0 ]\n",
      "[ 36.8 18.5 193.0 3500.0 ]\n",
      "[ 37.5 18.5 199.0 4475.0 ]\n",
      "[ 38.1 17.6 187.0 3425.0 ]\n",
      "[ 41.1 17.5 190.0 3900.0 ]\n",
      "[ 35.6 17.5 191.0 3175.0 ]\n",
      "[ 40.2 20.1 200.0 3975.0 ]\n",
      "[ 37.0 16.5 185.0 3400.0 ]\n",
      "[ 39.7 17.9 193.0 4250.0 ]\n",
      "[ 40.2 17.1 193.0 3400.0 ]\n",
      "[ 40.6 17.2 187.0 3475.0 ]\n",
      "[ 32.1 15.5 188.0 3050.0 ]\n",
      "[ 40.7 17.0 190.0 3725.0 ]\n",
      "[ 37.3 16.8 192.0 3000.0 ]\n",
      "[ 39.0 18.7 185.0 3650.0 ]\n",
      "[ 39.2 18.6 190.0 4250.0 ]\n",
      "[ 36.6 18.4 184.0 3475.0 ]\n",
      "[ 36.0 17.8 195.0 3450.0 ]\n",
      "[ 37.8 18.1 193.0 3750.0 ]\n",
      "[ 36.0 17.1 187.0 3700.0 ]\n",
      "[ 41.5 18.5 201.0 4000.0 ]\n",
      "[ 46.1 13.2 211.0 4500.0 ]\n",
      "[ 50.0 16.3 230.0 5700.0 ]\n",
      "[ 48.7 14.1 210.0 4450.0 ]\n",
      "[ 50.0 15.2 218.0 5700.0 ]\n",
      "[ 47.6 14.5 215.0 5400.0 ]\n",
      "[ 46.5 13.5 210.0 4550.0 ]\n",
      "[ 45.4 14.6 211.0 4800.0 ]\n",
      "[ 46.7 15.3 219.0 5200.0 ]\n",
      "[ 43.3 13.4 209.0 4400.0 ]\n",
      "[ 46.8 15.4 215.0 5150.0 ]\n",
      "[ 40.9 13.7 214.0 4650.0 ]\n",
      "[ 49.0 16.1 216.0 5550.0 ]\n",
      "[ 45.5 13.7 214.0 4650.0 ]\n",
      "[ 48.4 14.6 213.0 5850.0 ]\n",
      "[ 45.8 14.6 210.0 4200.0 ]\n",
      "[ 49.3 15.7 217.0 5850.0 ]\n",
      "[ 42.0 13.5 210.0 4150.0 ]\n",
      "[ 49.2 15.2 221.0 6300.0 ]\n",
      "[ 46.2 14.5 209.0 4800.0 ]\n",
      "[ 48.7 15.1 222.0 5350.0 ]\n",
      "[ 50.2 14.3 218.0 5700.0 ]\n",
      "[ 45.1 14.5 215.0 5000.0 ]\n",
      "[ 46.5 14.5 213.0 4400.0 ]\n",
      "[ 46.3 15.8 215.0 5050.0 ]\n",
      "[ 42.9 13.1 215.0 5000.0 ]\n",
      "[ 46.1 15.1 215.0 5100.0 ]\n",
      "[ 44.5 14.3 216.0 4100.0 ]\n",
      "[ 47.8 15.0 215.0 5650.0 ]\n",
      "[ 48.2 14.3 210.0 4600.0 ]\n",
      "[ 50.0 15.3 220.0 5550.0 ]\n",
      "[ 47.3 15.3 222.0 5250.0 ]\n",
      "[ 42.8 14.2 209.0 4700.0 ]\n",
      "[ 45.1 14.5 207.0 5050.0 ]\n",
      "[ 59.6 17.0 230.0 6050.0 ]\n",
      "[ 49.1 14.8 220.0 5150.0 ]\n",
      "[ 48.4 16.3 220.0 5400.0 ]\n",
      "[ 42.6 13.7 213.0 4950.0 ]\n",
      "[ 44.4 17.3 219.0 5250.0 ]\n",
      "[ 44.0 13.6 208.0 4350.0 ]\n",
      "[ 48.7 15.7 208.0 5350.0 ]\n",
      "[ 42.7 13.7 208.0 3950.0 ]\n",
      "[ 49.6 16.0 225.0 5700.0 ]\n",
      "[ 45.3 13.7 210.0 4300.0 ]\n",
      "[ 49.6 15.0 216.0 4750.0 ]\n",
      "[ 50.5 15.9 222.0 5550.0 ]\n",
      "[ 43.6 13.9 217.0 4900.0 ]\n",
      "[ 45.5 13.9 210.0 4200.0 ]\n",
      "[ 50.5 15.9 225.0 5400.0 ]\n",
      "[ 44.9 13.3 213.0 5100.0 ]\n",
      "[ 45.2 15.8 215.0 5300.0 ]\n",
      "[ 46.6 14.2 210.0 4850.0 ]\n",
      "[ 48.5 14.1 220.0 5300.0 ]\n",
      "[ 45.1 14.4 210.0 4400.0 ]\n",
      "[ 50.1 15.0 225.0 5000.0 ]\n",
      "[ 46.5 14.4 217.0 4900.0 ]\n",
      "[ 45.0 15.4 220.0 5050.0 ]\n",
      "[ 43.8 13.9 208.0 4300.0 ]\n",
      "[ 45.5 15.0 220.0 5000.0 ]\n",
      "[ 43.2 14.5 208.0 4450.0 ]\n",
      "[ 50.4 15.3 224.0 5550.0 ]\n",
      "[ 45.3 13.8 208.0 4200.0 ]\n",
      "[ 46.2 14.9 221.0 5300.0 ]\n",
      "[ 45.7 13.9 214.0 4400.0 ]\n",
      "[ 54.3 15.7 231.0 5650.0 ]\n",
      "[ 45.8 14.2 219.0 4700.0 ]\n",
      "[ 49.8 16.8 230.0 5700.0 ]\n",
      "[ 46.2 14.4 214.0 4650.0 ]\n",
      "[ 49.5 16.2 229.0 5800.0 ]\n",
      "[ 43.5 14.2 220.0 4700.0 ]\n",
      "[ 50.7 15.0 223.0 5550.0 ]\n",
      "[ 47.7 15.0 216.0 4750.0 ]\n",
      "[ 46.4 15.6 221.0 5000.0 ]\n",
      "[ 48.2 15.6 221.0 5100.0 ]\n",
      "[ 46.5 14.8 217.0 5200.0 ]\n",
      "[ 46.4 15.0 216.0 4700.0 ]\n",
      "[ 48.6 16.0 230.0 5800.0 ]\n",
      "[ 47.5 14.2 209.0 4600.0 ]\n",
      "[ 51.1 16.3 220.0 6000.0 ]\n",
      "[ 45.2 13.8 215.0 4750.0 ]\n",
      "[ 45.2 16.4 223.0 5950.0 ]\n",
      "[ 49.1 14.5 212.0 4625.0 ]\n",
      "[ 52.5 15.6 221.0 5450.0 ]\n",
      "[ 47.4 14.6 212.0 4725.0 ]\n",
      "[ 50.0 15.9 224.0 5350.0 ]\n",
      "[ 44.9 13.8 212.0 4750.0 ]\n",
      "[ 50.8 17.3 228.0 5600.0 ]\n",
      "[ 43.4 14.4 218.0 4600.0 ]\n",
      "[ 51.3 14.2 218.0 5300.0 ]\n",
      "[ 47.5 14.0 212.0 4875.0 ]\n",
      "[ 52.1 17.0 230.0 5550.0 ]\n",
      "[ 47.5 15.0 218.0 4950.0 ]\n",
      "[ 52.2 17.1 228.0 5400.0 ]\n",
      "[ 45.5 14.5 212.0 4750.0 ]\n",
      "[ 49.5 16.1 224.0 5650.0 ]\n",
      "[ 44.5 14.7 214.0 4850.0 ]\n",
      "[ 50.8 15.7 226.0 5200.0 ]\n",
      "[ 49.4 15.8 216.0 4925.0 ]\n",
      "[ 46.9 14.6 222.0 4875.0 ]\n",
      "[ 48.4 14.4 203.0 4625.0 ]\n",
      "[ 51.1 16.5 225.0 5250.0 ]\n",
      "[ 48.5 15.0 219.0 4850.0 ]\n",
      "[ 55.9 17.0 228.0 5600.0 ]\n",
      "[ 47.2 15.5 215.0 4975.0 ]\n",
      "[ 49.1 15.0 228.0 5500.0 ]\n",
      "[ 47.3 13.8 216.0 4725.0 ]\n",
      "[ 46.8 16.1 215.0 5500.0 ]\n",
      "[ 41.7 14.7 210.0 4700.0 ]\n",
      "[ 53.4 15.8 219.0 5500.0 ]\n",
      "[ 43.3 14.0 208.0 4575.0 ]\n",
      "[ 48.1 15.1 209.0 5500.0 ]\n",
      "[ 50.5 15.2 216.0 5000.0 ]\n",
      "[ 49.8 15.9 229.0 5950.0 ]\n",
      "[ 43.5 15.2 213.0 4650.0 ]\n",
      "[ 51.5 16.3 230.0 5500.0 ]\n",
      "[ 46.2 14.1 217.0 4375.0 ]\n",
      "[ 55.1 16.0 230.0 5850.0 ]\n",
      "[ 44.5 15.7 217.0 4875.0 ]\n",
      "[ 48.8 16.2 222.0 6000.0 ]\n",
      "[ 47.2 13.7 214.0 4925.0 ]\n",
      "[ nan nan nan nan ]\n",
      "[ 46.8 14.3 215.0 4850.0 ]\n",
      "[ 50.4 15.7 222.0 5750.0 ]\n",
      "[ 45.2 14.8 212.0 5200.0 ]\n",
      "[ 49.9 16.1 213.0 5400.0 ]\n",
      "[ 46.5 17.9 192.0 3500.0 ]\n",
      "[ 50.0 19.5 196.0 3900.0 ]\n",
      "[ 51.3 19.2 193.0 3650.0 ]\n",
      "[ 45.4 18.7 188.0 3525.0 ]\n",
      "[ 52.7 19.8 197.0 3725.0 ]\n",
      "[ 45.2 17.8 198.0 3950.0 ]\n",
      "[ 46.1 18.2 178.0 3250.0 ]\n",
      "[ 51.3 18.2 197.0 3750.0 ]\n",
      "[ 46.0 18.9 195.0 4150.0 ]\n",
      "[ 51.3 19.9 198.0 3700.0 ]\n",
      "[ 46.6 17.8 193.0 3800.0 ]\n",
      "[ 51.7 20.3 194.0 3775.0 ]\n",
      "[ 47.0 17.3 185.0 3700.0 ]\n",
      "[ 52.0 18.1 201.0 4050.0 ]\n",
      "[ 45.9 17.1 190.0 3575.0 ]\n",
      "[ 50.5 19.6 201.0 4050.0 ]\n",
      "[ 50.3 20.0 197.0 3300.0 ]\n",
      "[ 58.0 17.8 181.0 3700.0 ]\n",
      "[ 46.4 18.6 190.0 3450.0 ]\n",
      "[ 49.2 18.2 195.0 4400.0 ]\n",
      "[ 42.4 17.3 181.0 3600.0 ]\n",
      "[ 48.5 17.5 191.0 3400.0 ]\n",
      "[ 43.2 16.6 187.0 2900.0 ]\n",
      "[ 50.6 19.4 193.0 3800.0 ]\n",
      "[ 46.7 17.9 195.0 3300.0 ]\n",
      "[ 52.0 19.0 197.0 4150.0 ]\n",
      "[ 50.5 18.4 200.0 3400.0 ]\n",
      "[ 49.5 19.0 200.0 3800.0 ]\n",
      "[ 46.4 17.8 191.0 3700.0 ]\n",
      "[ 52.8 20.0 205.0 4550.0 ]\n",
      "[ 40.9 16.6 187.0 3200.0 ]\n",
      "[ 54.2 20.8 201.0 4300.0 ]\n",
      "[ 42.5 16.7 187.0 3350.0 ]\n",
      "[ 51.0 18.8 203.0 4100.0 ]\n",
      "[ 49.7 18.6 195.0 3600.0 ]\n",
      "[ 47.5 16.8 199.0 3900.0 ]\n",
      "[ 47.6 18.3 195.0 3850.0 ]\n",
      "[ 52.0 20.7 210.0 4800.0 ]\n",
      "[ 46.9 16.6 192.0 2700.0 ]\n",
      "[ 53.5 19.9 205.0 4500.0 ]\n",
      "[ 49.0 19.5 210.0 3950.0 ]\n",
      "[ 46.2 17.5 187.0 3650.0 ]\n",
      "[ 50.9 19.1 196.0 3550.0 ]\n",
      "[ 45.5 17.0 196.0 3500.0 ]\n",
      "[ 50.9 17.9 196.0 3675.0 ]\n",
      "[ 50.8 18.5 201.0 4450.0 ]\n",
      "[ 50.1 17.9 190.0 3400.0 ]\n",
      "[ 49.0 19.6 212.0 4300.0 ]\n",
      "[ 51.5 18.7 187.0 3250.0 ]\n",
      "[ 49.8 17.3 198.0 3675.0 ]\n",
      "[ 48.1 16.4 199.0 3325.0 ]\n",
      "[ 51.4 19.0 201.0 3950.0 ]\n",
      "[ 45.7 17.3 193.0 3600.0 ]\n",
      "[ 50.7 19.7 203.0 4050.0 ]\n",
      "[ 42.5 17.3 187.0 3350.0 ]\n",
      "[ 52.2 18.8 197.0 3450.0 ]\n",
      "[ 45.2 16.6 191.0 3250.0 ]\n",
      "[ 49.3 19.9 203.0 4050.0 ]\n",
      "[ 50.2 18.8 202.0 3800.0 ]\n",
      "[ 45.6 19.4 194.0 3525.0 ]\n",
      "[ 51.9 19.5 206.0 3950.0 ]\n",
      "[ 46.8 16.5 189.0 3650.0 ]\n",
      "[ 45.7 17.0 195.0 3650.0 ]\n",
      "[ 55.8 19.8 207.0 4000.0 ]\n",
      "[ 43.5 18.1 202.0 3400.0 ]\n",
      "[ 49.6 18.2 193.0 3775.0 ]\n",
      "[ 50.8 19.0 210.0 4100.0 ]\n",
      "[ 50.2 18.7 198.0 3775.0 ]\n"
     ]
    }
   ],
   "source": [
    "# Display a random sample of 10 observations\n",
    "sample = penguins.sample(10)\n",
    "sample\n",
    "penguin_classes = ['Adelie', 'Gentoo', 'Chinstrap']\n",
    "print(sample.columns[0:5].values, 'SpeciesName')\n",
    "for index, row in penguins.sample(3).iterrows():\n",
    "    print('[',row[0], row[1], row[2], row[3], int(row[4]),']',penguin_classes[int(row[4])])\n",
    "for index, row in penguins.iterrows():\n",
    "    print('[',row[0], row[1], row[2], row[3],']')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5c5d06",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d6d88a",
   "metadata": {},
   "source": [
    "#### Test the correlation between a variable StudyHours and Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0340055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.668110684836675"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normalized.Grade.corr(df_normalized.StudyHours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edef8ad",
   "metadata": {},
   "source": [
    "### Regression Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b5e69b",
   "metadata": {},
   "source": [
    "Loading the data for the Regression notebook, split into train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "201d5c16",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2803653908.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [43]\u001b[0;36m\u001b[0m\n\u001b[0;31m    X, y = bike_data.loc[,-1], [['season','mnth', 'holiday','weekday','workingday','weathersit','temp', 'atemp', 'hum', 'windspeed']].values, bike_data['rentals'].values\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = bike_data.loc[,-1], [['season','mnth', 'holiday','weekday','workingday','weathersit','temp', 'atemp', 'hum', 'windspeed']].values, bike_data['rentals'].values\n",
    "print('Features:',X[:3], '\\nLabels:', y[:3], sep='\\n')\n",
    "# Split data 70%-30% into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "print ('Training Set: %d rows\\nTest Set: %d rows' % (X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f491242",
   "metadata": {},
   "source": [
    "#### Fit a linear regression model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691d8693",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Fit a linear regression model on the training set\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027c3758",
   "metadata": {},
   "source": [
    "#### Using linear regression model to create predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17947cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "np.set_printoptions(suppress=True)\n",
    "print('Predicted labels: ', np.round(predictions)[:10])\n",
    "print('Actual labels   : ' ,y_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d999fd7b",
   "metadata": {},
   "source": [
    "#### Plot predicted versus actual rentals over a scatter plot, iwth the regression line overlaid: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a440291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Daily Bike Share Predictions')\n",
    "# overlay the regression line\n",
    "z = np.polyfit(y_test, predictions, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test,p(y_test), color='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa87d9c",
   "metadata": {},
   "source": [
    "#### Show Mean Squared Error (MSE), Root Mean Squared Error, and R2 Score: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf714e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"MSE:\", mse)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R2:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff62e78",
   "metadata": {},
   "source": [
    "#### LASSO regression: Train model, evalute using test data, plot actual versus predicted and regression line overlaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92411113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Fit a lasso model on the training set\n",
    "model = Lasso().fit(X_train, y_train)\n",
    "print (model, \"\\n\")\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"MSE:\", mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R2:\", r2)\n",
    "\n",
    "# Plot predicted vs actual\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Daily Bike Share Predictions')\n",
    "# overlay the regression line\n",
    "z = np.polyfit(y_test, predictions, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test,p(y_test), color='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b800585c",
   "metadata": {},
   "source": [
    "#### Decision Tree: Train model, evaluate, plot predicted versus actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fd171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "# Train the model\n",
    "model = DecisionTreeRegressor().fit(X_train, y_train)\n",
    "print (model, \"\\n\")\n",
    "\n",
    "# Visualize the model tree\n",
    "tree = export_text(model)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"MSE:\", mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R2:\", r2)\n",
    "\n",
    "# Plot predicted vs actual\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Daily Bike Share Predictions')\n",
    "# overlay the regression line\n",
    "z = np.polyfit(y_test, predictions, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test,p(y_test), color='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c4303b",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Estimator: Train the model, evaluate, plot predicted versus actual with regression line overlaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbcbd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "# Fit a Gradient Boosting model on the training set\n",
    "model = GradientBoostingRegressor().fit(X_train, y_train)\n",
    "print (model, \"\\n\")\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"MSE:\", mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R2:\", r2)\n",
    "\n",
    "# Plot predicted vs actual\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Daily Bike Share Predictions')\n",
    "# overlay the regression line\n",
    "z = np.polyfit(y_test, predictions, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test,p(y_test), color='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14639d37",
   "metadata": {},
   "source": [
    "#### Try different learning rates and n_estimators (trees) for Gradient Boosting, find the best model using GridSearch, print evaluation, and then plot predicted versus actual with regression line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21f2e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "\n",
    "# Use a Gradient Boosting algorithm\n",
    "alg = GradientBoostingRegressor()\n",
    "\n",
    "# Try these hyperparameter values\n",
    "params = {\n",
    " 'learning_rate': [0.1, 0.5, 1.0],\n",
    " 'n_estimators' : [50, 100, 150]\n",
    " }\n",
    "\n",
    "# Find the best hyperparameter combination to optimize the R2 metric\n",
    "score = make_scorer(r2_score)\n",
    "gridsearch = GridSearchCV(alg, params, scoring=score, cv=3, return_train_score=True)\n",
    "gridsearch.fit(X_train, y_train)\n",
    "print(\"Best parameter combination:\", gridsearch.best_params_, \"\\n\")\n",
    "\n",
    "# Get the best model\n",
    "model=gridsearch.best_estimator_\n",
    "print(model, \"\\n\")\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"MSE:\", mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R2:\", r2)\n",
    "\n",
    "# Plot predicted vs actual\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Daily Bike Share Predictions')\n",
    "# overlay the regression line\n",
    "z = np.polyfit(y_test, predictions, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test,p(y_test), color='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793a9374",
   "metadata": {},
   "source": [
    "#### Gradient Boosting: Create a pipeline that preprocesses data by scaling numeric columns and encoding categorical features as one-hot vectors, then applies a Gradient Boosting Regression and prints the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b86e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Define preprocessing for numeric columns (scale them)\n",
    "numeric_features = [6,7,8,9]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Define preprocessing for categorical features (encode them)\n",
    "categorical_features = [0,1,2,3,4,5]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Create preprocessing and training pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', GradientBoostingRegressor())])\n",
    "\n",
    "\n",
    "# fit the pipeline to train a linear regression model on the training set\n",
    "model = pipeline.fit(X_train, (y_train))\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae84e1b",
   "metadata": {},
   "source": [
    "#### Random Forest: Create a pipeline that preprocesses data by scaling numeric columns and encoding categorical features as one-hot vectors, then applies a Gradient Boosting Regression and prints the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1646cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a different estimator in the pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', RandomForestRegressor())])\n",
    "\n",
    "\n",
    "# fit the pipeline to train a linear regression model on the training set\n",
    "model = pipeline.fit(X_train, (y_train))\n",
    "print (model, \"\\n\")\n",
    "\n",
    "# Get predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Display metrics\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"MSE:\", mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R2:\", r2)\n",
    "\n",
    "# Plot predicted vs actual\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Daily Bike Share Predictions - Preprocessed')\n",
    "z = np.polyfit(y_test, predictions, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test,p(y_test), color='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa954af1",
   "metadata": {},
   "source": [
    "#### Save and reuse a regression model from a .pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4222d5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model as a pickle file\n",
    "filename = './bike-share.pkl'\n",
    "joblib.dump(model, filename)\n",
    "\n",
    "# Load the model from the file\n",
    "loaded_model = joblib.load(filename)\n",
    "\n",
    "# Create a numpy array containing a new observation (for example tomorrow's seasonal and weather forecast information)\n",
    "X_new = np.array([[1,1,0,3,1,1,0.226957,0.22927,0.436957,0.1869]]).astype('float64')\n",
    "print ('New sample: {}'.format(list(X_new[0])))\n",
    "\n",
    "# Use the model to predict tomorrow's rentals\n",
    "result = loaded_model.predict(X_new)\n",
    "print('Prediction: {:.0f} rentals'.format(np.round(result[0])))\n",
    "\n",
    "# Load the model from the file\n",
    "loaded_model = joblib.load(filename)\n",
    "\n",
    "# Create a numpy array containing a new observation (for example tomorrow's seasonal and weather forecast information)\n",
    "X_new = np.array([[1,1,0,3,1,1,0.226957,0.22927,0.436957,0.1869]]).astype('float64')\n",
    "print ('New sample: {}'.format(list(X_new[0])))\n",
    "\n",
    "# Use the model to predict tomorrow's rentals\n",
    "result = loaded_model.predict(X_new)\n",
    "print('Prediction: {:.0f} rentals'.format(np.round(result[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f5d714",
   "metadata": {},
   "source": [
    "### Classification Model - One Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a833b92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "features = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']\n",
    "label = 'Diabetic'\n",
    "X, y = diabetes[features].values, diabetes[label].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dc0d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data 70%-30% into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "print ('Training cases: %d\\nTest cases: %d' % (X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076d2fab",
   "metadata": {},
   "source": [
    "#### Train and apply a Logistic Regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cced297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Set regularization rate\n",
    "reg = 0.01\n",
    "\n",
    "# train a logistic regression model on the training set\n",
    "# regularization rate of 100 means L2 more prominent, can also set \"l1\" or \"l2\"\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "print (model)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print('Predicted labels: ', predictions)\n",
    "print('Actual labels:    ' ,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a98ad1",
   "metadata": {},
   "source": [
    "#### Evaluate logistic regression model, including precision, F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb0bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, predictions))\n",
    "\n",
    "from sklearn. metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601beb36",
   "metadata": {},
   "source": [
    "- Precision: Of the predictions the model made for this class, what proportion were correct?\n",
    "\n",
    "- Recall: Out of all of the instances of this class in the test dataset, how many did the model identify?\n",
    "\n",
    "- F1-Score: An average metric that takes both precision and recall into account.\n",
    "\n",
    "- Support: How many instances of this class are there in the test dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942d60db",
   "metadata": {},
   "source": [
    "#### Show overall precision and recall (important for multiple categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8ffc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(\"Overall Precision:\",precision_score(y_test, predictions))\n",
    "print(\"Overall Recall:\",recall_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e066ca",
   "metadata": {},
   "source": [
    "#### Show confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed49807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Print the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print (cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a524dd",
   "metadata": {},
   "source": [
    "#### Make predictions, plot ROC Curve, show AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bbbca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = model.predict_proba(X_test)\n",
    "print(y_scores)\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
    "\n",
    "# plot ROC curve\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "# Plot the diagonal 50% line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# Plot the FPR and TPR achieved by our model\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aeb60b",
   "metadata": {},
   "source": [
    "#### Create a pipeline that normalizes and one-hot encodes variables, then show metrics and plot ROC Curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e279b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# Define preprocessing for numeric columns (normalize them so they're on the same scale)\n",
    "numeric_features = [0,1,2,3,4,5,6]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Define preprocessing for categorical features (encode the Age column)\n",
    "categorical_features = [7]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Create preprocessing and training pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('logregressor', LogisticRegression(C=1/reg, solver=\"liblinear\"))])\n",
    "\n",
    "\n",
    "# fit the pipeline to train a logistic regression model on the training set\n",
    "model = pipeline.fit(X_train, (y_train))\n",
    "# print (model)\n",
    "\n",
    "# Get predictions from test data\n",
    "predictions = model.predict(X_test)\n",
    "y_scores = model.predict_proba(X_test)\n",
    "\n",
    "# Get evaluation metrics\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print ('Confusion Matrix:\\n',cm, '\\n')\n",
    "print('Accuracy:', accuracy_score(y_test, predictions))\n",
    "print(\"Overall Precision:\",precision_score(y_test, predictions))\n",
    "print(\"Overall Recall:\",recall_score(y_test, predictions))\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "\n",
    "# calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
    "\n",
    "# plot ROC curve\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "# Plot the diagonal 50% line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# Plot the FPR and TPR achieved by our model\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323c7ec6",
   "metadata": {},
   "source": [
    "#### Reuse the above Pipeline for Random Forest Classification and go through the same steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f93d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create preprocessing and training pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('logregressor', RandomForestClassifier(n_estimators=100))])\n",
    "\n",
    "# fit the pipeline to train a random forest model on the training set\n",
    "model = pipeline.fit(X_train, (y_train))\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "y_scores = model.predict_proba(X_test)\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print ('Confusion Matrix:\\n',cm, '\\n')\n",
    "print('Accuracy:', accuracy_score(y_test, predictions))\n",
    "print(\"Overall Precision:\",precision_score(y_test, predictions))\n",
    "print(\"Overall Recall:\",recall_score(y_test, predictions))\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('\\nAUC: ' + str(auc))\n",
    "\n",
    "# calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
    "\n",
    "# plot ROC curve\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "# Plot the diagonal 50% line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# Plot the FPR and TPR achieved by our model\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0a58ed",
   "metadata": {},
   "source": [
    "#### Save as a .pkl file, apply it, and print new predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12db3a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the model as a pickle file\n",
    "filename = './diabetes_model.pkl'\n",
    "joblib.dump(model, filename)\n",
    "# Load the model from the file\n",
    "model = joblib.load(filename)\n",
    "\n",
    "# predict on a new sample\n",
    "# The model accepts an array of feature arrays (so you can predict the classes of multiple patients in a single call)\n",
    "# We'll create an array with a single array of features, representing one patient\n",
    "X_new = np.array([[2,180,74,24,21,23.9091702,1.488172308,22]])\n",
    "print ('New sample: {}'.format(list(X_new[0])))\n",
    "\n",
    "# Get a prediction\n",
    "pred = model.predict(X_new)\n",
    "\n",
    "# The model returns an array of predictions - one for each set of features submitted\n",
    "# In our case, we only submitted one patient, so our prediction is the first one in the resulting array.\n",
    "print('Predicted class is {}'.format(pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d4a325",
   "metadata": {},
   "source": [
    "### Classification Model - Multiclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab61087",
   "metadata": {},
   "source": [
    "#### All of the preprocessing steps for a multiclass classification probelm: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59e18d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of the preprocessing steps with the penguins dataset: \n",
    "# Count the number of null values for each column\n",
    "penguins.isnull().sum()\n",
    "# Show rows containing nulls\n",
    "penguins[penguins.isnull().any(axis=1)]\n",
    "# Drop rows containing NaN values\n",
    "penguins=penguins.dropna()\n",
    "#Confirm there are now no nulls\n",
    "penguins.isnull().sum()\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot boxplots against labels for each species\n",
    "penguin_features = ['CulmenLength','CulmenDepth','FlipperLength','BodyMass']\n",
    "penguin_label = 'Species'\n",
    "for col in penguin_features:\n",
    "    penguins.boxplot(column=col, by=penguin_label, figsize=(6,6))\n",
    "    plt.title(col)\n",
    "plt.show()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features and labels\n",
    "penguins_X, penguins_y = penguins[penguin_features].values, penguins[penguin_label].values\n",
    "\n",
    "# Split data 70%-30% into training set and test set\n",
    "x_penguin_train, x_penguin_test, y_penguin_train, y_penguin_test = train_test_split(penguins_X, penguins_y,\n",
    "                                                                                    test_size=0.30,\n",
    "                                                                                    random_state=0,\n",
    "                                                                                    stratify=penguins_y)\n",
    "\n",
    "print ('Training Set: %d, Test Set: %d \\n' % (x_penguin_train.shape[0], x_penguin_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8d8c2b",
   "metadata": {},
   "source": [
    "#### Train a multi-class logistic regression model on the training set, make predictions, and show metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64603dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Set regularization rate\n",
    "reg = 0.1\n",
    "\n",
    "# train a logistic regression model on the training set\n",
    "multi_model = LogisticRegression(C=1/reg, solver='lbfgs', multi_class='auto', max_iter=10000).fit(x_penguin_train, y_penguin_train)\n",
    "print (multi_model)\n",
    "\n",
    "penguin_predictions = multi_model.predict(x_penguin_test)\n",
    "print('Predicted labels: ', penguin_predictions[:15])\n",
    "print('Actual labels   : ' ,y_penguin_test[:15])\n",
    "\n",
    "from sklearn. metrics import classification_report\n",
    "\n",
    "print(classification_report(y_penguin_test, penguin_predictions))\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(\"Overall Accuracy:\",accuracy_score(y_penguin_test, penguin_predictions))\n",
    "print(\"Overall Precision:\",precision_score(y_penguin_test, penguin_predictions, average='macro'))\n",
    "print(\"Overall Recall:\",recall_score(y_penguin_test, penguin_predictions, average='macro'))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Print the confusion matrix\n",
    "mcm = confusion_matrix(y_penguin_test, penguin_predictions)\n",
    "print(mcm)\n",
    "\n",
    "# Get class probability scores\n",
    "penguin_prob = multi_model.predict_proba(x_penguin_test)\n",
    "\n",
    "# Print average AUC\n",
    "auc = roc_auc_score(y_penguin_test,penguin_prob, multi_class='ovr')\n",
    "print('Average AUC:', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df133342",
   "metadata": {},
   "source": [
    "#### Create a Pipeline for processing, training, and making predictions from a multiclass classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e44e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define preprocessing for numeric columns (scale them)\n",
    "feature_columns = [0,1,2,3]\n",
    "feature_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "# Create preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('preprocess', feature_transformer, feature_columns)])\n",
    "\n",
    "# Create training pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', SVC(probability=True))])\n",
    "\n",
    "\n",
    "# fit the pipeline to train a linear regression model on the training set\n",
    "multi_model = pipeline.fit(x_penguin_train, y_penguin_train)\n",
    "print (multi_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c615f62b",
   "metadata": {},
   "source": [
    "#### See Visualization section for Heat Map confusion matrix and Multiclass ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d91fb7",
   "metadata": {},
   "source": [
    "### Clustering Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5175ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a random sample of 10 observations (just the features)\n",
    "data = pd.read_csv('seeds.csv')\n",
    "features = data[data.columns[0:6]]\n",
    "features.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4d30c9",
   "metadata": {},
   "source": [
    "#### Normalize the numeric features and use PCA to get two principle components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92814c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Normalize the numeric features so they're on the same scale\n",
    "scaled_features = MinMaxScaler().fit_transform(features[data.columns[0:6]])\n",
    "\n",
    "# Get two principal components\n",
    "pca = PCA(n_components=2).fit(scaled_features)\n",
    "features_2d = pca.transform(scaled_features)\n",
    "features_2d[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e95c413",
   "metadata": {},
   "source": [
    "#### After PCA, show datapoints on two dimensions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6a3f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.scatter(features_2d[:,0],features_2d[:,1])\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.title('Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bed1bb4",
   "metadata": {},
   "source": [
    "#### Plot Within Cluster Sum of Squares against clusters to estimate optimal number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ae2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "%matplotlib inline\n",
    "\n",
    "# Create 10 models with 1 to 10 clusters\n",
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters = i)\n",
    "    # Fit the data points\n",
    "    kmeans.fit(features.values)\n",
    "    # Get the WCSS (inertia) value\n",
    "    wcss.append(kmeans.inertia_)\n",
    "    \n",
    "#Plot the WCSS values onto a line graph\n",
    "plt.plot(range(1, 11), wcss)\n",
    "plt.title('WCSS by Clusters')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccec080a",
   "metadata": {},
   "source": [
    "#### Execute and Plot a K-Means clustering algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49552ae9",
   "metadata": {},
   "source": [
    "What are the advantages of K-Means versus hierarchical clustering?\n",
    "\n",
    "A: K-means requires more assumptions, but hierarchical clustering is much more computationally expensive, and thus less scalable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568406e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create a model based on 3 centroids\n",
    "model = KMeans(n_clusters=3, init='k-means++', n_init=100, max_iter=1000)\n",
    "# Fit to the data and predict the cluster assignments for each data point\n",
    "km_clusters = model.fit_predict(features.values)\n",
    "# View the cluster assignments\n",
    "km_clusters\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_clusters(samples, clusters):\n",
    "    col_dic = {0:'blue',1:'green',2:'orange'}\n",
    "    mrk_dic = {0:'*',1:'x',2:'+'}\n",
    "    colors = [col_dic[x] for x in clusters]\n",
    "    markers = [mrk_dic[x] for x in clusters]\n",
    "    for sample in range(len(clusters)):\n",
    "        plt.scatter(samples[sample][0], samples[sample][1], color = colors[sample], marker=markers[sample], s=100)\n",
    "    plt.xlabel('Dimension 1')\n",
    "    plt.ylabel('Dimension 2')\n",
    "    plt.title('Assignments')\n",
    "    plt.show()\n",
    "\n",
    "plot_clusters(features_2d, km_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8952b444",
   "metadata": {},
   "source": [
    "#### Execute and plot a Hierarchical / Agglomerative Clustering Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8d2c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "agg_model = AgglomerativeClustering(n_clusters=3)\n",
    "agg_clusters = agg_model.fit_predict(features.values)\n",
    "agg_clusters\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_clusters(samples, clusters):\n",
    "    col_dic = {0:'blue',1:'green',2:'orange'}\n",
    "    mrk_dic = {0:'*',1:'x',2:'+'}\n",
    "    colors = [col_dic[x] for x in clusters]\n",
    "    markers = [mrk_dic[x] for x in clusters]\n",
    "    for sample in range(len(clusters)):\n",
    "        plt.scatter(samples[sample][0], samples[sample][1], color = colors[sample], marker=markers[sample], s=100)\n",
    "    plt.xlabel('Dimension 1')\n",
    "    plt.ylabel('Dimension 2') \n",
    "    plt.title('Assignments')\n",
    "    plt.show()\n",
    "\n",
    "plot_clusters(features_2d, agg_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f664eb7",
   "metadata": {},
   "source": [
    "### Deep Learning Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5980bef",
   "metadata": {},
   "source": [
    "#### Do preword: Import dataset, oversample to increase its size, split into train/test, set datatypes to float and categorical, and set a random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3162e407",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = pd.read_csv('penguins.csv').dropna()\n",
    "\n",
    "# Deep Learning models work best when features are on similar scales\n",
    "# In a real solution, we'd implement some custom normalization for each feature, but to keep things simple\n",
    "# we'll just rescale the FlipperLength and BodyMass so they're on a similar scale to the bill measurements\n",
    "penguins['FlipperLength'] = penguins['FlipperLength']/10\n",
    "penguins['BodyMass'] = penguins['BodyMass']/100\n",
    "\n",
    "# The dataset is too small to be useful for deep learning\n",
    "# So we'll oversample it to increase its size\n",
    "for i in range(1,3):\n",
    "    penguins = penguins.append(penguins)\n",
    "    \n",
    "penguin_classes = ['Adelie', 'Gentoo', 'Chinstrap']\n",
    "#print(sample.columns[0:5].values, 'SpeciesName')\n",
    "#for index, row in penguins.sample(10).iterrows():\n",
    "#    print('[',row[0], row[1], row[2],row[3], int(row[4]), ']',penguin_classes[int(row[-1])])\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = ['CulmenLength','CulmenDepth','FlipperLength','BodyMass']\n",
    "label = 'Species'\n",
    "   \n",
    "# Split data 70%-30% into training set and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(penguins[features].values,\n",
    "                                                    penguins[label].values,\n",
    "                                                    test_size=0.30,\n",
    "                                                    random_state=0)\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# Set random seed for reproducability\n",
    "tensorflow.random.set_seed(0)\n",
    "\n",
    "print(\"Libraries imported.\")\n",
    "print('Keras version:',keras.__version__)\n",
    "print('TensorFlow version:',tensorflow.__version__)\n",
    "\n",
    "# Set data types for float features\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Set data types for categorical labels\n",
    "y_train = utils.to_categorical(y_train)\n",
    "y_test = utils.to_categorical(y_test)\n",
    "print('Ready...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed219583",
   "metadata": {},
   "source": [
    "#### Define a classified network with a rectification linear activation function, a hidden layer with ten input nodes, and an output layer with a SoftMax activiation function that predicts penguin species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5572f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a classifier network\n",
    "hl = 10 # Number of hidden layer nodes\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(hl, input_dim=len(features), activation='relu'))\n",
    "model.add(Dense(hl, input_dim=hl, activation='relu'))\n",
    "model.add(Dense(len(penguin_classes), input_dim=hl, activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6395914d",
   "metadata": {},
   "source": [
    "#### Train the above model by applying an Adam optimizer to a categorical cross-entropy loss function interatively over 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5a68ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#hyper-parameters for optimizer\n",
    "learning_rate = 0.001\n",
    "opt = optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model over 50 epochs using 10-observation batches and using the test holdout dataset for validation\n",
    "num_epochs = 50\n",
    "history = model.fit(x_train, y_train, epochs=num_epochs, batch_size=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183e0457",
   "metadata": {},
   "source": [
    "#### Use matplot to show how the loss increased over iterations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60657f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "epoch_nums = range(1,num_epochs+1)\n",
    "training_loss = history.history[\"loss\"]\n",
    "validation_loss = history.history[\"val_loss\"]\n",
    "plt.plot(epoch_nums, training_loss)\n",
    "plt.plot(epoch_nums, validation_loss)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93d7e2b",
   "metadata": {},
   "source": [
    "#### Show how the weights changed for each layer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f91bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()[0]\n",
    "    biases = layer.get_weights()[1]\n",
    "    #print('------------\\nWeights:\\n',weights,'\\nBiases:\\n', biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd032b03",
   "metadata": {},
   "source": [
    "#### Evaluate model performance by showing a confusion matrix: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa9123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow doesn't have a built-in confusion matrix metric, so we'll use SciKit-Learn\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "class_probabilities = model.predict(x_test)\n",
    "predictions = np.argmax(class_probabilities, axis=1)\n",
    "true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(penguin_classes))\n",
    "plt.xticks(tick_marks, penguin_classes, rotation=85)\n",
    "plt.yticks(tick_marks, penguin_classes)\n",
    "plt.xlabel(\"Predicted Species\")\n",
    "plt.ylabel(\"Actual Species\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb615d54",
   "metadata": {},
   "source": [
    "#### Save the trained neural network as an .h5 file and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce5671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "modelFileName = 'models/penguin-classifier.h5'\n",
    "model.save(modelFileName)\n",
    "del model  # deletes the existing model variable\n",
    "print('model saved as', modelFileName)\n",
    "\n",
    "# Load the saved model\n",
    "model = models.load_model(modelFileName)\n",
    "\n",
    "# CReate a new array of features\n",
    "x_new = np.array([[50.4,15.3,20,50]])\n",
    "print ('New sample: {}'.format(x_new))\n",
    "\n",
    "# Use the model to predict the class\n",
    "class_probabilities = model.predict(x_new)\n",
    "predictions = np.argmax(class_probabilities, axis=1)\n",
    "\n",
    "print(penguin_classes[predictions[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4f91c6",
   "metadata": {},
   "source": [
    "#### Prepare se a transfer learning algorithm to distinguish between shapes stored as .png files in separate folders by importing the data, showing the different shapes, and splitting into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b9c87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# The images are in the data/shapes folder\n",
    "data_folder = 'data/shapes'\n",
    "\n",
    "# Get the class names\n",
    "classes = os.listdir(data_folder)\n",
    "classes.sort()\n",
    "print(len(classes), 'classes:')\n",
    "print(classes)\n",
    "\n",
    "# Show the first image in each folder\n",
    "fig = plt.figure(figsize=(8, 12))\n",
    "i = 0\n",
    "for sub_dir in os.listdir(data_folder):\n",
    "    i+=1\n",
    "    img_file = os.listdir(os.path.join(data_folder,sub_dir))[0]\n",
    "    img_path = os.path.join(data_folder, sub_dir, img_file)\n",
    "    img = mpimg.imread(img_path)\n",
    "    a=fig.add_subplot(1, len(classes),i)\n",
    "    a.axis('off')\n",
    "    imgplot = plt.imshow(img)\n",
    "    a.set_title(img_file)\n",
    "plt.show()\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "img_size = (128, 128)\n",
    "batch_size = 30\n",
    "\n",
    "print(\"Getting Data...\")\n",
    "datagen = ImageDataGenerator(rescale=1./255, # normalize pixel values\n",
    "                             validation_split=0.3) # hold back 30% of the images for validation\n",
    "\n",
    "print(\"Preparing training dataset...\")\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_folder,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training') # set as training data\n",
    "\n",
    "print(\"Preparing validation dataset...\")\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_folder,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation') # set as validation data\n",
    "\n",
    "classnames = list(train_generator.class_indices.keys())\n",
    "print('Data generators ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c878839b",
   "metadata": {},
   "source": [
    "#### Define a convolutional netural network with an input layer, max pooling layer, ReLu activation function, SoftMax output layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6e4e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a CNN classifier network\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "\n",
    "# Define the model as a sequence of layers\n",
    "model = Sequential()\n",
    "\n",
    "# The input layer accepts an image and applies a convolution that uses 32 6x6 filters and a rectified linear unit activation function\n",
    "model.add(Conv2D(32, (6, 6), input_shape=train_generator.image_shape, activation='relu'))\n",
    "\n",
    "# Next we'll add a max pooling layer with a 2x2 patch\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# We can add as many layers as we think necessary - here we'll add another convolution and max pooling layer\n",
    "model.add(Conv2D(32, (6, 6), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# And another set\n",
    "model.add(Conv2D(32, (6, 6), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# A dropout layer randomly drops some nodes to reduce inter-dependencies (which can cause over-fitting)\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Flatten the feature maps \n",
    "model.add(Flatten())\n",
    "\n",
    "# Generate a fully-connected output layer with a predicted probability for each class\n",
    "# (softmax ensures all probabilities sum to 1)\n",
    "model.add(Dense(train_generator.num_classes, activation='softmax'))\n",
    "\n",
    "# With the layers defined, we can now compile the model for categorical (multi-class) classification\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a1c723",
   "metadata": {},
   "source": [
    "#### Train the CNN, view the loss history, and evaluate model performance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31aa6e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#Train the model over 5 epochs using 30-image batches and using the validation holdout dataset for validation\n",
    "num_epochs = 5\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // batch_size,\n",
    "    epochs = num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b2e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "epoch_nums = range(1,num_epochs+1)\n",
    "training_loss = history.history[\"loss\"]\n",
    "validation_loss = history.history[\"val_loss\"]\n",
    "plt.plot(epoch_nums, training_loss)\n",
    "plt.plot(epoch_nums, validation_loss)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8501cca0",
   "metadata": {},
   "source": [
    "#### Show a confusion matrix, save file, and deploy with a random test image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a1f83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow doesn't have a built-in confusion matrix metric, so we'll use SciKit-Learn\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Generating predictions from validation data...\")\n",
    "# Get the image and label arrays for the first batch of validation data\n",
    "x_test = validation_generator[0][0]\n",
    "y_test = validation_generator[0][1]\n",
    "\n",
    "# Use the model to predict the class\n",
    "class_probabilities = model.predict(x_test)\n",
    "\n",
    "# The model returns a probability value for each class\n",
    "# The one with the highest probability is the predicted class\n",
    "predictions = np.argmax(class_probabilities, axis=1)\n",
    "\n",
    "# The actual labels are hot encoded (e.g. [0 1 0], so get the one with the value 1\n",
    "true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classnames))\n",
    "plt.xticks(tick_marks, classnames, rotation=85)\n",
    "plt.yticks(tick_marks, classnames)\n",
    "plt.xlabel(\"Predicted Shape\")\n",
    "plt.ylabel(\"Actual Shape\")\n",
    "plt.show()\n",
    "\n",
    "# Save the trained model\n",
    "modelFileName = 'models/shape_classifier.h5'\n",
    "model.save(modelFileName)\n",
    "del model  # deletes the existing model variable\n",
    "print('model saved as', modelFileName)\n",
    "\n",
    "from tensorflow.keras import models\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# Function to predict the class of an image\n",
    "def predict_image(classifier, image):\n",
    "    from tensorflow import convert_to_tensor\n",
    "    # The model expects a batch of images as input, so we'll create an array of 1 image\n",
    "    imgfeatures = image.reshape(1, image.shape[0], image.shape[1], image.shape[2])\n",
    "\n",
    "    # We need to format the input to match the training data\n",
    "    # The generator loaded the values as floating point numbers\n",
    "    # and normalized the pixel values, so...\n",
    "    imgfeatures = imgfeatures.astype('float32')\n",
    "    imgfeatures /= 255\n",
    "    \n",
    "    # Use the model to predict the image class\n",
    "    class_probabilities = classifier.predict(imgfeatures)\n",
    "    \n",
    "    # Find the class predictions with the highest predicted probability\n",
    "    index = int(np.argmax(class_probabilities, axis=1)[0])\n",
    "    return index\n",
    "\n",
    "# Function to create a random image (of a square, circle, or triangle)\n",
    "def create_image (size, shape):\n",
    "    from random import randint\n",
    "    import numpy as np\n",
    "    from PIL import Image, ImageDraw\n",
    "    \n",
    "    xy1 = randint(10,40)\n",
    "    xy2 = randint(60,100)\n",
    "    col = (randint(0,200), randint(0,200), randint(0,200))\n",
    "\n",
    "    img = Image.new(\"RGB\", size, (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    if shape == 'circle':\n",
    "        draw.ellipse([(xy1,xy1), (xy2,xy2)], fill=col)\n",
    "    elif shape == 'triangle':\n",
    "        draw.polygon([(xy1,xy1), (xy2,xy2), (xy2,xy1)], fill=col)\n",
    "    else: # square\n",
    "        draw.rectangle([(xy1,xy1), (xy2,xy2)], fill=col)\n",
    "    del draw\n",
    "    \n",
    "    return np.array(img)\n",
    "\n",
    "# Create a random test image\n",
    "classnames = os.listdir(os.path.join('data', 'shapes'))\n",
    "classnames.sort()\n",
    "img = create_image ((128,128), classnames[randint(0, len(classnames)-1)])\n",
    "plt.axis('off')\n",
    "plt.imshow(img)\n",
    "\n",
    "# Use the classifier to predict the class\n",
    "model = models.load_model(modelFileName) # loads the saved model\n",
    "class_idx = predict_image(model, img)\n",
    "print (classnames[class_idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5ffd05",
   "metadata": {},
   "source": [
    "### Plots and Visualizations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7756ad00",
   "metadata": {},
   "source": [
    "Okay to review the above, to start:\n",
    "- import the df_students from Github using wget and read with a .csv\n",
    "- remove any rows iwth missing data\n",
    "- Calculate who passed, assuming 60 is neeed to pass\n",
    "- Added the passes as a column \n",
    "- print the result out into the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de4b856",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "\n",
    "# Load data from a text file\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/ml-basics/grades.csv\n",
    "df_students = pd.read_csv('grades.csv',delimiter=',',header='infer')\n",
    "\n",
    "# Remove any rows with missing data\n",
    "df_students = df_students.dropna(axis=0, how='any')\n",
    "\n",
    "# Calculate who passed, assuming '60' is the grade needed to pass\n",
    "passes  = pd.Series(df_students['Grade'] >= 60)\n",
    "\n",
    "# Save who passed to the Pandas dataframe\n",
    "df_students = pd.concat([df_students, passes.rename(\"Pass\")], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948b5c75",
   "metadata": {},
   "source": [
    "#### Setting the figures to show in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b97a9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c378b8",
   "metadata": {},
   "source": [
    "#### Using Matplot, Create a bar plot of two variables, where x is categorical and y is numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1c199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine the dimensions of the figure\n",
    "fig = plt.figure(figsize=(8,3))\n",
    "\n",
    "# Create a bar plot of name vs grade\n",
    "plt.bar(x=df_students.Name, height=df_students.Grade, color='orange')\n",
    "\n",
    "# Customize the chart\n",
    "plt.title('Student Grades')\n",
    "plt.xlabel('Student')\n",
    "plt.ylabel('Grade')\n",
    "plt.grid(color='#95a5a6', linestyle='--', linewidth=2, axis='y', alpha=0.7)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9895fed3",
   "metadata": {},
   "source": [
    "#### Using Matplot, Create a pie chart of counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33b1005",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine the dimensions of the figure\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "\n",
    "pass_counts = df_students['Pass'].value_counts()\n",
    "\n",
    "# Create a bar plot of name vs grade\n",
    "plt.pie(pass_counts, labels=pass_counts)\n",
    "\n",
    "# Customize the chart\n",
    "plt.title('Student Grades')\n",
    "plt.xlabel('Student')\n",
    "plt.ylabel('Grade')\n",
    "plt.grid(color='#95a5a6', linestyle='--', linewidth=2, axis='y', alpha=0.7)\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(pass_counts.keys().tolist())\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162fba86",
   "metadata": {},
   "source": [
    "#### Using Matplot, Create Two Plots side by side: One a bar chart as above, one a pie chart that shows counts of another variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297e79d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure for 2 subplots (1 row, 2 columns)\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10,4))\n",
    "\n",
    "# Create a bar plot of name vs grade on the first axis\n",
    "ax[0].bar(x=df_students.Name, height=df_students.Grade, color='orange')\n",
    "ax[0].set_title('Grades')\n",
    "ax[0].set_xticklabels(df_students.Name, rotation=90)\n",
    "\n",
    "# Create a pie chart of pass counts on the second axis\n",
    "pass_counts = df_students['Pass'].value_counts()\n",
    "ax[1].pie(pass_counts, labels=pass_counts)\n",
    "ax[1].set_title('Passing Grades')\n",
    "ax[1].legend(pass_counts.keys().tolist())\n",
    "\n",
    "# Add a title to the Figure\n",
    "fig.suptitle('Student Data')\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98ebf61",
   "metadata": {},
   "source": [
    "#### Using Matplot, create a histogram from a Pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d14d69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_data = df_students['Grade']\n",
    "fig = plt.figure(figsize=(10,4))\n",
    "plt.hist(var_data)\n",
    "plt.title('Data Distribution')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece30173",
   "metadata": {},
   "source": [
    "#### Add axis lines for mean, median, mode, etc. to the above histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f1f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = df_students['Grade']\n",
    "\n",
    "# Get the statistics\n",
    "min_val = var.min()\n",
    "max_val = var.max()\n",
    "mean_val = var.mean()\n",
    "med_val = var.median()\n",
    "mod_val = var.mode()[0]\n",
    "\n",
    "#Create a Figure\n",
    "fig = plt.figure(figsize=(10,4))\n",
    "\n",
    "# Plot a histogram\n",
    "plt.hist(var)\n",
    "\n",
    "# Add the lines\n",
    "plt.axvline(x=min_val, color = 'gray', linestyle = 'dashed', linewidth = 2)\n",
    "plt.axvline(x=mean_val, color = 'cyan', linestyle='dashed', linewidth = 2)\n",
    "plt.axvline(x=med_val, color = 'red', linestyle='dashed', linewidth = 2)\n",
    "plt.axvline(x=mod_val, color = 'yellow', linestyle='dashed', linewidth = 2)\n",
    "plt.axvline(x=max_val, color = 'gray', linestyle='dashed', linewidth = 2)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Data Distribution')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cb5929",
   "metadata": {},
   "source": [
    "#### Using Matplot, create a boxplot from a Pandas series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988bec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the variable to examine\n",
    "var = df_students['Grade']\n",
    "\n",
    "# Create a Figure\n",
    "fig = plt.figure(figsize=(10,4))\n",
    "\n",
    "# Plot a histogram\n",
    "plt.boxplot(var)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Data Distribution')\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f759c7",
   "metadata": {},
   "source": [
    "#### Using Matplot, superimpose the histogram and Box plot on top of one another: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494ce3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that we can re-use\n",
    "def show_distribution(var_data):\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    # Get statistics\n",
    "    min_val = var_data.min()\n",
    "    max_val = var_data.max()\n",
    "    mean_val = var_data.mean()\n",
    "    med_val = var_data.median()\n",
    "    mod_val = var_data.mode()[0]\n",
    "\n",
    "    #print('Minimum:{:.2f}\\nMean:{:.2f}\\nMedian:{:.2f}\\nMode:{:.2f}\\nMaximum:{:.2f}\\n'.format(min_val,mean_val,med_val,max_val)  \n",
    "    # Create a figure for 2 subplots (2 rows, 1 column)\n",
    "    fig, ax = plt.subplots(2, 1, figsize = (10,4))\n",
    "\n",
    "    # Plot the histogram   \n",
    "    ax[0].hist(var_data)\n",
    "    ax[0].set_ylabel('Frequency')\n",
    "\n",
    "    # Add lines for the mean, median, and mode\n",
    "    ax[0].axvline(x=min_val, color = 'gray', linestyle='dashed', linewidth = 2)\n",
    "    ax[0].axvline(x=mean_val, color = 'cyan', linestyle='dashed', linewidth = 2)\n",
    "    ax[0].axvline(x=med_val, color = 'red', linestyle='dashed', linewidth = 2)\n",
    "    ax[0].axvline(x=mod_val, color = 'yellow', linestyle='dashed', linewidth = 2)\n",
    "    ax[0].axvline(x=max_val, color = 'gray', linestyle='dashed', linewidth = 2)\n",
    "\n",
    "    # Plot the boxplot   \n",
    "    ax[1].boxplot(var_data, vert=False)\n",
    "    ax[1].set_xlabel('Value')\n",
    "\n",
    "    # Add a title to the Figure\n",
    "    fig.suptitle('Data Distribution')\n",
    "\n",
    "    # Show the figure\n",
    "    fig.show()\n",
    "\n",
    "# Get the variable to examine\n",
    "col = df_students['Grade']\n",
    "# Call the function\n",
    "show_distribution(col)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640dae03",
   "metadata": {},
   "source": [
    "#### Using Matplot, show a density diagram from a Pandas series: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06682cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_density(var_data):\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    fig = plt.figure(figsize=(10,4))\n",
    "\n",
    "    # Plot density\n",
    "    var_data.plot.density()\n",
    "\n",
    "    # Add titles and labels\n",
    "    plt.title('Data Density')\n",
    "\n",
    "    # Show the mean, median, and mode\n",
    "    plt.axvline(x=var_data.mean(), color = 'cyan', linestyle='dashed', linewidth = 2)\n",
    "    plt.axvline(x=var_data.median(), color = 'red', linestyle='dashed', linewidth = 2)\n",
    "    plt.axvline(x=var_data.mode()[0], color = 'yellow', linestyle='dashed', linewidth = 2)\n",
    "\n",
    "    # Show the figure\n",
    "    plt.show()\n",
    "\n",
    "# Get the density of Grade\n",
    "col = df_students['Grade']\n",
    "show_density(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4d3006",
   "metadata": {},
   "source": [
    "#### Create a bar chart in one line from the dataframe and set a new label for the y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a730aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = df_students.plot.bar(x='Name', y ='StudyHours', color = 'teal', figsize=(6,4), title = \"Study Hours by Student\")\n",
    "plot.set_ylabel(\"Study Hours\") \n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1699cf50",
   "metadata": {},
   "source": [
    "#### Show a distribution of a Pandas series: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c156bada",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = df_students[df_students.StudyHours>1]['StudyHours']\n",
    "show_distribution(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d4eb65",
   "metadata": {},
   "source": [
    "#### Use SciPy Stats to set a Gaussian distribution for a Pandas Series and annotate 1st, 2nd, and 3rd standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c625455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Get the grade column from df_students\n",
    "col = df_students['Grade']\n",
    "\n",
    "#Get and plot the density \n",
    "density = stats.gaussian_kde(col) \n",
    "\n",
    "col.plot.density()\n",
    "\n",
    "#Get the mean and standards deviation\n",
    "s = col.std()\n",
    "m = col.mean()\n",
    "\n",
    "#Annotate 1 stdev\n",
    "\n",
    "x1 = [m-s, m+s]\n",
    "y1 = density(x1)\n",
    "plt.plot(x1,y1, color = 'magenta')\n",
    "plt.annotate('1 std (68.26 %)',  (x1[1],y1[1]))\n",
    "\n",
    "# Annotate 2 stdevs\n",
    "x2 = [m-(s*2), m+(s*2)]\n",
    "y2 = density(x2)\n",
    "plt.plot(x2,y2, color='green')\n",
    "plt.annotate('2 std (95.45%)', (x2[1],y2[1]))\n",
    "\n",
    "# Annotate 3 stdevs\n",
    "x3 = [m-(s*3), m+(s*3)]\n",
    "y3 = density(x3)\n",
    "plt.plot(x3,y3, color='orange')\n",
    "plt.annotate('3 std (99.73%)', (x3[1],y3[1]))\n",
    "\n",
    "# Show the location of the mean\n",
    "plt.axvline(col.mean(), color='cyan', linestyle='dashed', linewidth=1)\n",
    "\n",
    "#plt.axis('off')\n",
    "\n",
    "plt.title(\"Distribution of Grades\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce058111",
   "metadata": {},
   "source": [
    "#### Create a bar plot showing two values side-by-side, in this case, normalized ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349d99df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the normalized values\n",
    "df_normalized.plot(x='Name', y=['Grade','StudyHours'], kind='bar', figsize=(8,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a21d50",
   "metadata": {},
   "source": [
    "#### Create a Scatter Plot from a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7b93fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot\n",
    "df_sample.plot.scatter(title='Study Time vs Grade', x='StudyHours', y='Grade')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee890ee3",
   "metadata": {},
   "source": [
    "#### Create a histogram from a Pandas dataframe and set bins "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bca0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = var.plot.hist(bins=10, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d9ebe7",
   "metadata": {},
   "source": [
    "#### Loop through numerical features in a dataframe and plot histograms for each, with median and mean axis lines: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4fedb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram for each numeric feature\n",
    "numeric_features = ['temp', 'atemp', 'hum', 'windspeed']\n",
    "for col in numeric_features:\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    ax = fig.gca()\n",
    "    feature = bike_data[col]\n",
    "    feature.hist(bins=100, ax = ax)\n",
    "    ax.axvline(feature.mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
    "    ax.axvline(feature.median(), color='cyan', linestyle='dashed', linewidth=2)\n",
    "    ax.set_title(col)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9926ff5b",
   "metadata": {},
   "source": [
    "#### Loop through the categorical features of a dataframe and create a histogram for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df5acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# plot a bar plot for each categorical feature count\n",
    "categorical_features = ['season','mnth','holiday','weekday','workingday','weathersit', 'day']\n",
    "\n",
    "for col in categorical_features:\n",
    "    counts = bike_data[col].value_counts().sort_index()\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    ax = fig.gca()\n",
    "    counts.plot.bar(ax = ax, color='steelblue')\n",
    "    ax.set_title(col + ' counts')\n",
    "    ax.set_xlabel(col) \n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6c22f2",
   "metadata": {},
   "source": [
    "#### Loop through the numerical features of a dataframe and create scatter plots against the target variable, including correlation in the title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d15e311",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numeric_features:\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    ax = fig.gca()\n",
    "    feature = bike_data[col]\n",
    "    label = bike_data['rentals']\n",
    "    correlation = feature.corr(label)\n",
    "    plt.scatter(x=feature, y=label)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Bike Rentals')\n",
    "    ax.set_title('rentals vs ' + col + '- correlation: ' + str(correlation))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e35ca09",
   "metadata": {},
   "source": [
    "#### Loop through the categorical features of a dataframe and create boxplots against a target variable: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ae30b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a boxplot for the label by each categorical feature\n",
    "for col in categorical_features:\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    ax = fig.gca()\n",
    "    bike_data.boxplot(column = 'rentals', by = col, ax = ax)\n",
    "    ax.set_title('Label by ' + col)\n",
    "    ax.set_ylabel(\"Bike Rentals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767a6e61",
   "metadata": {},
   "source": [
    "#### For classification exploration, loop through features and create a boxplot for each category: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560e3f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "features = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']\n",
    "for col in features:\n",
    "    diabetes.boxplot(column=col, by='Diabetic', figsize=(6,6))\n",
    "    plt.title(col)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43631516",
   "metadata": {},
   "source": [
    "#### Show a Confusion Matrix visualization for a multiclass classification problem: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b6cc42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(mcm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(penguin_classes))\n",
    "plt.xticks(tick_marks, penguin_classes, rotation=45)\n",
    "plt.yticks(tick_marks, penguin_classes)\n",
    "plt.xlabel(\"Predicted Species\")\n",
    "plt.ylabel(\"Actual Species\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db763052",
   "metadata": {},
   "source": [
    "#### Plot a ROC Curve for each class in a multiclass classification problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498fb3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Get class probability scores\n",
    "penguin_prob = multi_model.predict_proba(x_penguin_test)\n",
    "\n",
    "# Get ROC metrics for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "thresh ={}\n",
    "for i in range(len(penguin_classes)):    \n",
    "    fpr[i], tpr[i], thresh[i] = roc_curve(y_penguin_test, penguin_prob[:,i], pos_label=i)\n",
    "    \n",
    "# Plot the ROC chart\n",
    "plt.plot(fpr[0], tpr[0], linestyle='--',color='orange', label=penguin_classes[0] + ' vs Rest')\n",
    "plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label=penguin_classes[1] + ' vs Rest')\n",
    "plt.plot(fpr[2], tpr[2], linestyle='--',color='blue', label=penguin_classes[2] + ' vs Rest')\n",
    "plt.title('Multiclass ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7d8be3",
   "metadata": {},
   "source": [
    "#### For clustering analysis, after PCA, show a plot of the two dimensions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ce164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "data = pd.read_csv('seeds.csv')\n",
    "\n",
    "# Display a random sample of 10 observations (just the features)\n",
    "features = data[data.columns[0:6]]\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Normalize the numeric features so they're on the same scale\n",
    "scaled_features = MinMaxScaler().fit_transform(features[data.columns[0:6]])\n",
    "\n",
    "# Get two principal components\n",
    "pca = PCA(n_components=2).fit(scaled_features)\n",
    "features_2d = pca.transform(scaled_features)\n",
    "features_2d[0:10]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.scatter(features_2d[:,0],features_2d[:,1])\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.title('Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f59490d",
   "metadata": {},
   "source": [
    "# Appendix: Script with examples for Python code like Class/function generation, __main__, decorators, and logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ce01cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat May 21 15:04:52 2022\n",
    "\n",
    "@author: chriswickham\n",
    "\n",
    "This file creates a function for each of the 38 Practice \n",
    "Problems in Practice Python\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "These are answers for these 38 Python practice questions: \n",
    "    https://www.practicepython.org/\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from datetime import date, datetime\n",
    "import pandas as pd\n",
    "import logging, coloredlogs\n",
    "import random\n",
    "import string\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# WHen you're done with all of these quesitons, you should \n",
    "# make sure to do something that explores decorators. \n",
    "\n",
    "def question_announcer(func): \n",
    "    \n",
    "    def inner(self): \n",
    "        print(\"%\" * 15)\n",
    "        print(\"This is the answer to \", func.__name__)\n",
    "        print(\"%\" * 15)\n",
    "        func(self)\n",
    "        \n",
    "    return inner\n",
    "\n",
    "class PythonPractice():\n",
    "    \n",
    "    def __init__(self): \n",
    "        pass\n",
    "\n",
    "    def question1(self, repeats = 0):\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        Question 1:\n",
    "        Create a program that asks the user to enter their name and their age. \n",
    "        Print out a message addressed to them that tells them the year that they will turn 100 years old. \n",
    "        \n",
    "        Add on to the previous program by asking the user for another number and printing out that many copies of the previous message. \n",
    "        (Hint: order of operations exists in Python)\n",
    "        Print out that many copies of the previous message on separate lines. \n",
    "        (Hint: the string \"\\n is the same as pressing the ENTER button)\n",
    "        Arguments\n",
    "        -------\n",
    "        None, requests a name (str) as input\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        Prints a message back to the console\n",
    "    \n",
    "        \"\"\"\n",
    "        logging.info('The answer to Question 1:')\n",
    "        logging.info('=====================================')\n",
    "        name = input(\"Give me your name: \")\n",
    "        print(\"Pleasure to meet you, \", name, \"!\")\n",
    "        \n",
    "        age = int(input(\"What is your age? \"))\n",
    "        \n",
    "        today = date.today()\n",
    "        \n",
    "        year = today.year\n",
    "        \n",
    "        target_year = year + (100 - age)\n",
    "        \n",
    "        print(\"You will turn 100 in\", target_year, \"\\n\")\n",
    "        \n",
    "        if repeats != 0: \n",
    "            for repeat in range(repeats): \n",
    "                print(\"You will turn 100 in\", target_year,\"\\n\")\n",
    "    \n",
    "    @question_announcer\n",
    "    def question2(self):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        Prints a message back to the console\n",
    "        \"\"\"\n",
    "        logging.info('The answer to Question 2:')\n",
    "        logging.info('=====================================')\n",
    "        number = int(input(\"What is the first number you choose? \"))\n",
    "        \n",
    "        if number % 2 == 0: \n",
    "            if number % 4 == 0: \n",
    "                print(\"Your number is even and divisble by 4.\")\n",
    "            else: \n",
    "                print(\"Your number is even.\")\n",
    "        else:\n",
    "            print(\"Your number is odd.\")\n",
    "        \n",
    "        num = int(input(\"What is the second number you choose? \"))\n",
    "        check = int(input(\"What is the number you want to divide it by? \"))\n",
    "        \n",
    "        if num % check == 0: \n",
    "            print(num, \"is divisible by\", check)\n",
    "        else: \n",
    "            print(num, \"is not divisible by\", check, \".\")\n",
    "    \n",
    "    def question3(self, list): \n",
    "        \"\"\"\n",
    "        - Take a list of integers and print all less than 5 (do this first\n",
    "        step in just one line of python).  \n",
    "        - Return a new list that is those elements of less than 5. \n",
    "       \n",
    "        Parameters\n",
    "        ----------\n",
    "        list : list\n",
    "            A list of numbers\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        Prints the old and the new list\n",
    "    \n",
    "        \"\"\"\n",
    "        \n",
    "        logging.info('The answer to Question 3:')\n",
    "        logging.info('=====================================')\n",
    "        #Creating the demo list\n",
    "        print(\"This is the list to begin with: \\n\", list)\n",
    "        print(\"This is the list now: \\n\")\n",
    "        # list comprehension to create the new list\n",
    "        newlist = [i for i in list if i<5]\n",
    "        print(newlist)\n",
    "        # Establish min and max to be able to filter\n",
    "        minv = min(list)\n",
    "        maxv = max(list)\n",
    "        # Seek input\n",
    "        new_number = int(input(f'For extra credit, give me a number between {minv} and {maxv}:'))\n",
    "        # Filter and print the new list \n",
    "        newlist2 = [i for i in list if i < new_number]\n",
    "        print(\"This is the new list with items less than that number:\", newlist2)\n",
    "    \n",
    "    def question4(self): \n",
    "        \"\"\"\n",
    "        Create a program that asks the user for a number and then prints out a list of all the divisors of that number.\n",
    "        \n",
    "        Arguments\n",
    "        -------\n",
    "        None\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        Prints a list of divisors for that number\n",
    "    \n",
    "        \"\"\"\n",
    "        logging.info('The answer to Question 4:')\n",
    "        logging.info('=====================================')\n",
    "        num = int(input(\"Choose a number and we'll determine divisors:\"))\n",
    "        newlist = [i for i in range(1,num+1) if num % i == 0]\n",
    "        newlist = ' '.join(str(i) for i in newlist)\n",
    "        print(newlist)\n",
    "     \n",
    "    def question5(self):\n",
    "        \"\"\"\n",
    "        Take two lists and write a program that returns a list that contains only \n",
    "        the elements that are common between the lists (without duplicates). \n",
    "        Make sure your program works on two lists of different sizes.\n",
    "    \n",
    "        Extras:\n",
    "    \n",
    "        Randomly generate two lists to test this\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list1: list\n",
    "            This is a list of integers\n",
    "        list2: list\n",
    "            This is a list of integers\n",
    "        \"\"\"    \n",
    "        logging.info('The answer to Question 5:')\n",
    "        logging.info('=====================================')\n",
    "        list1 = []\n",
    "        list2 = []\n",
    "        for i in range(random.randint(1,10)): \n",
    "            list1.append(random.randint(4,15))\n",
    "        for i in range(random.randint(1,10)): \n",
    "            list2.append(random.randint(1,10))\n",
    "            \n",
    "        newlist = [i for i in list1 if i in list2]\n",
    "        print(\"This is the first randomly generated list: \\n\", list1)\n",
    "        print(\"This is the second randomly generated list: \\n\", list2)   \n",
    "        print(\"This is the list of overlapping items: \\n\", newlist)\n",
    "        \n",
    "    def question6(self): \n",
    "        \"\"\"\n",
    "        Ask the user for a string and print out whether this string is a palindrome or not. \n",
    "        (A palindrome is a string that reads the same forwards and backwards.)\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "    \n",
    "        \"\"\"\n",
    "        logging.info('The answer to Question 6:')\n",
    "        logging.info('=====================================')\n",
    "        string = input(\"What word should be try to see if it's a palindrome:\")\n",
    "        string2 = string[::-1]\n",
    "        if string == string2: \n",
    "            print(string, \" is a palindrome.\")\n",
    "        else: \n",
    "            print(string, \" is not a palindrome.\")\n",
    "            \n",
    "        # Note, when you're slicing strings, the first argument is where you start, \n",
    "        # The second argument is where you end, and the third shows the direction and/or\n",
    "        # steps, where negative means backwards\n",
    "        # Related see these, where you can count by steps (but don't include the last item):\n",
    "        # \n",
    "        #   a = [5, 10, 15, 20, 25, 30, 35, 40]\n",
    "        #   a[1:5:2]\n",
    "        #   >>> [10, 20]\n",
    "        #   a[3:0:-1]\n",
    "        #   >>> [15, 10, 5]\n",
    "        \n",
    "    def question7(self,list): \n",
    "        \"\"\"\n",
    "        Letâ€™s say I give you a list saved in a variable: \n",
    "            a = [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]. \n",
    "        Write one line of Python that takes this list a and makes a new list that has only the even elements of this list in it.\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "    \n",
    "        \"\"\"\n",
    "        logging.info('The answer to Question 7:')\n",
    "        logging.info('=====================================')\n",
    "        print(\"This is the original list for question 7: \\n\", list)\n",
    "        newlist = [i for i in list if i % 2 == 0]\n",
    "        print(\"This is the list with only  even numbers:\\n\", newlist)\n",
    "    \n",
    "    def quit_protocol(self): \n",
    "        \"\"\"\n",
    "        This is a function that supports the question8 by providing options\n",
    "        for quitting the game.\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        Options for quitting rock paper scissors and soliciting input. \n",
    "    \n",
    "        \"\"\"\n",
    "        quit = input(\"Would you like to play again? Type yes or no.\")\n",
    "        if quit == \"yes\": \n",
    "            question8() \n",
    "        elif quit == \"no\":\n",
    "            print(\"Thanks for playing!\")\n",
    "            exit()\n",
    "        \n",
    "    def rps_protocol(self): \n",
    "        \"\"\"\n",
    "        \n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        plr2 : str\n",
    "            The answer for player 1: rock, paper, or scissers\n",
    "        plr1 : str\n",
    "            The answer for playe r2: rock, paper, or scissors\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        prints results to the console\n",
    "    \n",
    "        \"\"\"\n",
    "        tie = \"It's a tie\"\n",
    "        plr1 = \"Player 1 Wins!\"\n",
    "        plr2 = \"Player 2 Wins!\"\n",
    "        player1 = input(\"Player 1, rock, paper, or scissors?\").lower()\n",
    "        player2 = input(\"Player 2, rock, paper, or scissors?\").lower()\n",
    "        if player1 == \"rock\": \n",
    "            if player2 == \"rock\": \n",
    "                print(tie)\n",
    "            if player2 == \"scissors\" :\n",
    "                print(plr1)\n",
    "            if player2 == \"paper\":\n",
    "                print(plr2)\n",
    "        elif player1 == \"scissors\": \n",
    "            if player2 == \"rock\": \n",
    "                print(plr2)\n",
    "            if player2 == \"scissors\" :\n",
    "                print(tie)\n",
    "            if player2 == \"paper\":\n",
    "                print(plr1)\n",
    "        elif player1 == \"paper\": \n",
    "            if player2 == \"rock\": \n",
    "                print(plr1)\n",
    "            if player2 == \"scissors\" :\n",
    "                print(plr2)\n",
    "            if player2 == \"paper\":\n",
    "                print(tie)\n",
    "        if player1 not in [\"rock\", \"scissors\", \"paper\"] or player2 not in [\"rock\", \"scissors\", \"paper\"]:         \n",
    "                answer = input(\"The viable options are rock, paper, or scissors. Did you choose one of those?\")\n",
    "                if answer == \"yes\":\n",
    "                    print(\"LIAR\")\n",
    "                if answer == \"no\":\n",
    "                    quit_protocol()\n",
    "                    \n",
    "        # Note: Return jumps you up a level, exit() completely stops the program running, break breaks and while loops\n",
    "    \n",
    "    def question8(self): \n",
    "        \"\"\"\n",
    "        Make a two-player Rock-Paper-Scissors game.\n",
    "        \n",
    "        Arguments: \n",
    "            None (takes user input strings, Rock, Paper, or Scissors)\n",
    "        \n",
    "        Returns: \n",
    "            None (prints game output to console)\n",
    "        \"\"\"\n",
    "        logging.info('The answer to Question 8:')\n",
    "        logging.info('=====================================')\n",
    "        logging.info('Rock-Paper-Scissors commence!')\n",
    "        \n",
    "        # Play the game\n",
    "        self.rps_protocol()\n",
    "        \n",
    "        #Determine whether to play again\n",
    "        self.quit_protocol()\n",
    "    \n",
    "    def question9(self): \n",
    "        \"\"\"\n",
    "        Generate a random number between 1 and 9 (including 1 and 9). Ask the user to guess the number, \n",
    "        then tell them whether they guessed too low, too high, or exactly right. \n",
    "        (Hint: remember to use the user input lessons from the very first exercise)\n",
    "        Keep the game going until the user types â€œexitâ€\n",
    "        Keep track of how many guesses the user has taken, and when the game ends, print this out.\n",
    "        \n",
    "        Arguments: \n",
    "            None\n",
    "        Returns: \n",
    "            None\n",
    "        \"\"\"\n",
    "        logging.info('The answer to Question 9:')\n",
    "        logging.info('=====================================')\n",
    "        logging.info('Let the guessing game commence!')\n",
    "        \n",
    "        num = random.randint(1,9)\n",
    "        num_guess = 0\n",
    "        \n",
    "        guess = int(input(\"Guess a number between 1 and 9.\"))\n",
    "        while num != guess: \n",
    "            if guess < num: \n",
    "                print(\"The guess was too low.\") \n",
    "                num_guess += 1\n",
    "                guess = int(input(\"What's your new guess?\"))\n",
    "            elif guess > num: \n",
    "                print(\"Your guess was too high.\")\n",
    "                num_guess += 1\n",
    "                guess = int(input(\"What's your new guess?\"))\n",
    "            \n",
    "        print(\"You got it right!\")\n",
    "        \n",
    "        quit = input(\"Would you like to play again? Type yes or no.\")\n",
    "        if quit == \"yes\": \n",
    "            question9() \n",
    "        elif quit == \"no\":\n",
    "            print(\"Thanks for playing!\")\n",
    "            exit()    \n",
    "            \n",
    "    # Not doing a question 10 because I solved using a list comprehension in question 7\n",
    "    \n",
    "    def question11(self): \n",
    "        \"\"\"\n",
    "        Ask the user for a number and determine whether the number is prime or not.\n",
    "        \n",
    "        Arguments: \n",
    "            None, takes user input\n",
    "            \n",
    "        Returns: \n",
    "            None, prints whether the number is prime or not\n",
    "        \"\"\"\n",
    "        \n",
    "        logging.info('The answer to Question 11:')\n",
    "        logging.info('=====================================')\n",
    "        num = int(input(\"Choose a number and we'll determine whether it's prime:\"))\n",
    "        newlist = [i for i in range(1,num+1) if num % i == 0]\n",
    "        if len(newlist) != 2: \n",
    "            print(\"This number is not prime.\")\n",
    "        else: \n",
    "            print(\"This number is prime.\")\n",
    "            \n",
    "    def question12(self, list): \n",
    "        \"\"\"\n",
    "        Write a program that takes a list of numbers (for example, a = [5, 10, 15, 20, 25]) \n",
    "        and makes a new list of only the first and last elements of the given list. \n",
    "        For practice, write this code inside a function.\n",
    "        \n",
    "        Arguments\n",
    "        -------\n",
    "        list: list \n",
    "            A list of numbers\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        newlist: list \n",
    "            A new list consisting of only the first and last elements of the given list\n",
    "        \"\"\"\n",
    "        logging.info('The answer to Question 12:')\n",
    "        logging.info('=====================================')\n",
    "        print(\"This is the original list: \\n\", list)\n",
    "        newlist = [list[0], list[len(list)-1]]\n",
    "        print(\"This is the new list: \\n\", newlist)\n",
    "        \n",
    "    def question13(self): \n",
    "        \"\"\"\n",
    "        Write a program that asks the user how many Fibonnaci numbers to generate and then generates them. \n",
    "        \n",
    "        Arguments: \n",
    "            None, asks user to enter in number of Fibbonacci to generate\n",
    "        \n",
    "        Returns: \n",
    "            none, prints to the console\n",
    "        \"\"\"\n",
    "        logging.info('The answer to Question 13:')\n",
    "        logging.info('=====================================')\n",
    "        count = int(input(\"How far along on the Fibonnacci sequence would you like to count? \"))\n",
    "        list = [0,1]\n",
    "        if count == 1: \n",
    "            print(\"This is the Fibonnaci seqeunce :\", list[0])\n",
    "        elif count == 2: \n",
    "            print(\"This is the Fibonnaci seqeunce :\", list)\n",
    "        else: \n",
    "            iter =  0\n",
    "            while iter != count: \n",
    "                newnum = list[-1] + list[-2]\n",
    "                list.append(newnum)\n",
    "                iter += 1\n",
    "            print(\"This is the Fibbonacci sequence: \", list[:-1])\n",
    "            \n",
    "    def question14(self, list):\n",
    "        \"\"\"\n",
    "            Write a program (function!) that takes a list and returns a new list that contains all the elements of the first list minus all the duplicates.\n",
    "            Extras:\n",
    "            Write two different functions to do this - one using a loop and constructing a list, and another using sets.\n",
    "            Go back and do Exercise 5 using sets, and write the solution for that in a different function.\n",
    "            \n",
    "            Arguments\n",
    "            -------\n",
    "            list: list\n",
    "                A list from which to remove duplicates\n",
    "            Returns: \n",
    "            --------\n",
    "            newlist: list \n",
    "                The list with duplicates removed\n",
    "            newset: set\n",
    "                A set of the list with duplicates removed\n",
    "                \n",
    "        \"\"\"\n",
    "\n",
    "        print(\"For question 14, this is the original list: \\n\", list)\n",
    "        newlist = []\n",
    "        for i in list: \n",
    "            if i not in newlist: \n",
    "                newlist.append(i)\n",
    "        \n",
    "        print(\"For question 14, this is the new list: \\n\", newlist)\n",
    "        \n",
    "        newset = set(list)\n",
    "        \n",
    "        print(\"For question 14, this is the solution using a set: \\n\", newset)\n",
    "        \n",
    "        return(newlist, newset)\n",
    "        \n",
    "        \n",
    "    # A few notes: \n",
    "    #     Sets are not ordered. This means that there is no â€œfirst elementâ€ or â€œlast element.â€ There are just â€œelementsâ€. You cannot ask a set for itâ€™s â€œnext elementâ€.\n",
    "    #     There are no repeat elements in sets.\n",
    "    #     You can convert between sets and lists very easily.\n",
    "        \n",
    "    def question15(self): \n",
    "        \"\"\"\n",
    "        Write a program (using functions!) that asks the user for a long string containing multiple words. \n",
    "        Print back to the user the same string, except with the words in backwards order. \n",
    "        \n",
    "        Arguments: \n",
    "            None, user input\n",
    "\n",
    "        Returns\n",
    "            None, prints output to terminal \n",
    "        \"\"\"\n",
    "        sentence = input(\"Give a sentence to reverse order: \")\n",
    "        sentlist = sentence.split(\" \")\n",
    "        newsentencelist = sentlist[::-1]\n",
    "        newsentence = ' '.join(newsentencelist)\n",
    "        \n",
    "        print(\"This is your new sentence: \", newsentence)\n",
    "        \n",
    "    def question16(self): \n",
    "        \"\"\"\n",
    "        Write a password generator in Python. Be creative with how you generate passwords - \n",
    "        strong passwords have a mix of lowercase letters, uppercase letters, numbers, and symbols. \n",
    "        The passwords should be random, generating a new password every time the user asks for a new password.\n",
    "        Include your run-time code in a main method.\n",
    "        Extra:\n",
    "        Ask the user how strong they want their password to be. For weak passwords, pick a word or two from a list.\n",
    "\n",
    "        Arguments\n",
    "        -------\n",
    "        None (asks for user input)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Password: str\n",
    "            A password which is either strong or weak, based on user input\n",
    "        \"\"\"\n",
    "        upper_string = string.ascii_uppercase\n",
    "        lower_string = string.ascii_lowercase\n",
    "        special_characters = ['~', ':', \"'\", '+', '[', '\\\\', '@', '^', '{', '%', '(', '-', '\"', '*', '|', ',', '&', '<', '`', '}', '.', '_', '=', ']', '!', '>', ';', '?', '#', '$', ')', '/']\n",
    "        master_list = [upper_string, lower_string, special_characters]\n",
    "        weak_words = [\"orange\", \"yellow\", \"blue\", \"green\", \"red\", \"indigo\"]\n",
    "        \n",
    "        weakstrong = input(\"Do you want a weak password or a strong one? \" )\n",
    "        if weakstrong == \"weak\": \n",
    "            num = random.randint(0,5)\n",
    "            password = weak_words[num]\n",
    "            password = ''.join(password)\n",
    "            print(\"Your new password is: \", password)\n",
    "            return(password)\n",
    "        elif weakstrong == \"strong\": \n",
    "            password = []\n",
    "            num = random.randint(10,20)\n",
    "            iter = 0 \n",
    "            while iter != num: \n",
    "                source_num = random.randint(0,2)\n",
    "                character_num = random.randint(0,25)\n",
    "                password.append(master_list[source_num][character_num])\n",
    "                iter += 1\n",
    "        password = ''.join(password)\n",
    "        print(\"Your new password is: \", password)\n",
    "        return(password)\n",
    "    \n",
    "    def question17(self): \n",
    "        \"\"\"\n",
    "        Arguments: \n",
    "        -------\n",
    "            None, input\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            None (prints output to terminal)\n",
    "\n",
    "        \"\"\"\n",
    "        url = \"https://www.nytimes.com/\"\n",
    "        print(\"We'll be pinging this URL: \\n\", url)\n",
    "        r = requests.get(url)\n",
    "        print(\"This was the result of a get request: \\n\", r)\n",
    "        r_html = r.text\n",
    "        print(\"This is the html text: \\n\", r_html)\n",
    "        soup = BeautifulSoup(r_html)\n",
    "        title = soup.find(\"title\")\n",
    "        print(\"These are the titles of the homepage: \\n\", title)\n",
    "        \n",
    "    def question18(self): \n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        print(\"Welcome to the cows and bulls game!\")\n",
    "        num = random.randint(1000,9999)\n",
    "        print(\"Chris - the number is \", num)\n",
    "        num = str(num)\n",
    "        guess = input(\"What is your guess for a four digit number?\")\n",
    "        if len(guess) != 4: \n",
    "            guess = input(\"What is your next guess for a *four* digit number?\")\n",
    "        while guess != num: \n",
    "            cows = 0\n",
    "            bulls = 0\n",
    "            for i in range(0,4):\n",
    "                if guess[i] == num[i]: \n",
    "                    cows += 1\n",
    "                elif guess[i] in num: \n",
    "                    bulls+=1\n",
    "            print(\"You have \",cows, \"cows and \", bulls, \" bulls. Try again!\")\n",
    "            guess = input(\"What is your next guess for a four digit number?\")\n",
    "            if len(guess) != 4: \n",
    "                guess = input(\"What is your next guess for a *four* digit number?\")\n",
    "        print(\"You got it right!\" )\n",
    "                \n",
    "        \n",
    "def main(): \n",
    "    print(\"You've executed the main function! See the following script for how one might instantiate a class, call individual functions, and test performance time.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6683b820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun May 22 12:20:03 2022\n",
    "\n",
    "@author: chriswickham\n",
    "\"\"\"\n",
    "\n",
    "from datetime import date, datetime\n",
    "import pandas as pd\n",
    "import logging, coloredlogs\n",
    "import random\n",
    "import time\n",
    "\n",
    "from PythonPractice38Questions import PythonPractice \n",
    "# question1 = PythonPractice.question1()\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    start_time = time.time()\n",
    "    coloredlogs.install()\n",
    "    # logging.info('Get ready for answers to all of your questions')\n",
    "    # logging.info('=====================================')\n",
    "    # Setting demo variables \n",
    "    list = [1,2,3,4,5,6,7,8,9,10, 10]\n",
    "    # Initiating the pythonPractice class\n",
    "    # practicesesh = PythonPractice()\n",
    "    # practicesesh.question1()\n",
    "    #practicesesh.question2()\n",
    "    # practicesesh.question3(list)\n",
    "    # practicesesh.question4()\n",
    "    # practicesesh.question5()\n",
    "    # practicesesh.question6()\n",
    "    # practicesesh.question7(list)\n",
    "    # practicesesh. question8()\n",
    "    # practicesesh.question9()\n",
    "    # Not doing question 10 since I already solved in question 7\n",
    "    # practicesesh.question11()\n",
    "    # practicesesh.question12(list)\n",
    "    # practicesesh.question13()\n",
    "    # practicesesh.question14(list)\n",
    "    # practicesesh.question15()\n",
    "    # practicesesh.question16()\n",
    "    # practicesesh.question17()\n",
    "    # practicesesh.question18()\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
